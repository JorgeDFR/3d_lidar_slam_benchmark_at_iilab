# Usage

The benchmark process involves the following steps:

1. Download the IILABS 3D dataset
2. Set up the Docker environment
3. Run SLAM algorithms on the dataset
4. Evaluate the results

## 1. Download the IILABS 3D Dataset

The IILABS 3D dataset is available at the [INESC TEC research data repository](https://rdm.inesctec.pt/dataset/nis-2025-001). You can download it manually or use the IILABS 3D toolkit for easier access.

### Using the IILABS 3D Toolkit

The [IILABS 3D Toolkit](https://github.com/JorgeDFR/iilabs3d-toolkit) provides utilities for working with the dataset.

#### Installation

```bash
pip install iilabs3d-toolkit
```

!!! tip "Autocompletion"
    You can install autocompletion for the toolkit by running:
    ```bash
    iilabs3d --install-completion
    ```
    Restart your shell for the autocompletion to take effect.

#### Downloading Sequences

To download a specific sequence for a specific sensor:

```bash
iilabs3d download <output_directory> <sequence_name> <sensor_name>
```

For example, to download the "loop" benchmark sequence for the Livox Mid-360 sensor:

```bash
iilabs3d download ~/data bench/loop livox_mid-360
```

To download all benchmark sequences for all sensors:

```bash
iilabs3d download ~/data bench all
```

!!! info "Dataset Structure"
    The sequences will be saved in the following structure:
    ```
    <output_directory>/iilabs3d-dataset/<sequence_prefix>/<sensor_name>/<sequence_name>/
    ```

## 2. Set Up the Docker Environment

The benchmark uses Docker to ensure a consistent environment for all SLAM algorithms. This approach guarantees reproducibility and simplifies the setup process.

### Prerequisites

- :material-docker: [Docker](https://docs.docker.com/get-docker/) installed on your system
- :material-harddisk: At least 10GB of free disk space
- :material-memory: 16GB RAM recommended for optimal performance

!!! info "Guide for installing Docker and other tools in Ubuntu 20.04"
    For more detailed information about the Docker installation and additional setups, please refer to the [Install Docker](install_docker.md) section.

### Clone the Repository

```bash
git clone https://github.com/JorgeDFR/3d_lidar_slam_benchmark_at_iilab.git
cd 3d_lidar_slam_benchmark_at_iilab/docker
```

### Build and Run Docker Containers

#### Build Docker Images

```bash
# Build the image for ROS 1 (for A-LOAM, LeGO-LOAM-BOR, LIORF, DLIO)
docker compose build ros1_noetic

# Build the image for ROS 2 (for KISS-ICP, Kinematic-ICP, GLIM, VineSLAM, MOLA-LO)
docker compose build ros2_humble
```

#### Start Docker Containers

```bash
# Start ROS 1 container
docker compose up ros1_noetic -d

# Start ROS 2 container
docker compose up ros2_humble -d

# Or start both containers
docker compose up -d
```

#### Access Docker Containers

```bash
# Access ROS 1 container
docker exec -it 3d_slam_ros1 bash

# Access ROS 2 container
docker exec -it 3d_slam_ros2 bash
```

!!! warning "GUI Applications"
    Before running RViz inside the Docker container, you need to set up `xhost`:
    ```bash
    ./docker/setup_xhost.sh
    ```

## 3. Run SLAM Algorithms on the Dataset

### ROS 1 Algorithms

Inside the ROS 1 container:

```bash
# Set environment variables
export SLAM_CONF=aloam  # Options: aloam, lego_loam_bor, liorf, dlio
export SLAM_SENSOR=velodyne_vlp_16  # Options: velodyne_vlp_16, ouster_os1_64, robosense_rs_helios_5515, livox_mid_360

# Start the SLAM algorithm
roslaunch slam_benchmark_ros1_conf slam_benchmark.launch

# In another terminal, play the rosbag
rosbag play <path_to_bagfile>.bag
```

### ROS 2 Algorithms

Inside the ROS 2 container:

```bash
# Set environment variables
export SLAM_CONF=kiss_icp  # Options: kiss_icp, kinematic_icp, glim, vineslam, mola_lo
export SLAM_SENSOR=velodyne_vlp_16  # Options: velodyne_vlp_16, ouster_os1_64, robosense_rs_helios_5515, livox_mid_360

# Start the SLAM algorithm
ros2 launch slam_benchmark_ros2_conf slam_benchmark.launch.xml

# In another terminal, play the rosbag
ros2 bag play <path_to_bagfile>
```

### Offline Processing Mode

Several SLAM algorithms support an offline mode that processes rosbag files faster than real-time:

```bash
# ROS 1
roslaunch slam_benchmark_ros1_conf slam_benchmark.launch run_offline:=true rosbag_path:=<rosbag_file_path>

# ROS 2
ros2 launch slam_benchmark_ros2_conf slam_benchmark.launch.xml run_offline:=true rosbag_path:=<rosbag_file_path>
```

!!! note "Supported Algorithms for Offline Mode"
    The following algorithms currently support offline processing:
    
    - LeGO-LOAM-BOR
    - GLIM
    - Kinematic-ICP
    - MOLA-LO

## 4. Record and Evaluate Results

### Recording Odometry Trajectories

To capture the odometry trajectory generated by the SLAM algorithms:

```bash
# ROS 1
rosbag record -O <output_bag_file_name> /slam_odom

# ROS 2
ros2 bag record -o <output_bag_file_name> /slam_odom
```

!!! warning "MOLA-LO Special Case"
    For MOLA-LO, use the following command:
    ```bash
    # Set environment variable to use the LiDAR frame instead of base_link
    export MOLA_USE_FIXED_LIDAR_POSE=true
    
    mola-lidar-odometry-cli \
        -c $(ros2 pkg prefix mola_lidar_odometry)/share/mola_lidar_odometry/pipelines/lidar3d-default.yaml \
        --input-rosbag2 <path_to_bag_file> \
        --lidar-sensor-label <lidar_topic> \
        --output-tum-path <output_file_path>
    ```
    
    - `<path_to_bag_file>`: Path to your input rosbag file
    - `<lidar_topic>`: LiDAR sensor topic name (`/eve/ouster/points` for Ouster sequences or `/eve/lidar3d` for other sensors)
    - `<output_file_path>`: Desired path for the TUM-formatted trajectory output

### Converting to TUM Format

If your odometry trajectory is not in TUM format, you can convert it using the evo toolkit:

```bash
evo_traj bag <bag_file_name> <topic_name> --save_as_tum
```

### Evaluating Trajectories

Use the IILABS 3D toolkit to evaluate the trajectory against the ground truth:

```bash
iilabs3d eval <ground_truth.tum> <odometry.tum>
```

This will calculate metrics including Absolute Trajectory Error (ATE), Relative Translational Error (RTE), and Relative Rotational Error (RRE).

## Benchmark Results

The benchmark evaluates nine state-of-the-art 3D LiDAR-based SLAM algorithms:

1. **A-LOAM**: An advanced implementation of LOAM (Lidar Odometry and Mapping)
2. **LeGO-LOAM-BOR**: A fork of LeGO-LOAM with good software engineering practices to make the code more readable and efficient
3. **LIORF**: A fork of LIO-SAM which removes the feature extraction module and makes it easier to adapt other sensors
4. **DLIO**: A lightweight LiDAR-Inertial Odometry (LIO) algorithm with a coarse-to-fine approach in constructing continuous-time trajectories for precise motion correction
5. **VineSLAM**: A localization and mapping algorithm designed for challenging agricultural environments
6. **KISS-ICP**: An LiDAR Odometry ICP pipeline with the KISS principle (Keep It Simple and Scalable)
7. **GLIM**: An versatile and extensible range-based 3D mapping framework
8. **Kinematic-ICP**: An LiDAR Odometry ICP pipeline with kinematic constraints for wheeled robots
9. **MOLA-LO**: A modular optimization framework for localization and mapping using LiDAR Odometry (LO)

For detailed benchmark results, please refer to the [Benchmark Results](../benchmark/results/index.md) section.