{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Indoor Benchmark of 3D LiDAR SLAM at iilab - Industry and Innovation Laboratory","text":"<p>Abstract</p> <p>This paper presents the IILABS 3D \u2013 iilab Indoor LiDAR-based SLAM~3D dataset, a novel and publicly available resource designed to address current limitations in indoor benchmarking of 3D Light Detection And Ranging (LiDAR)-based Simultaneous Localization and Mapping (SLAM) algorithms. Existing SLAM datasets often focus on outdoor environments, rely on a single type of LiDAR sensor, or lack ground-truth data suitable for evaluating diverse indoor conditions. IILABS 3D fills this gap by providing a sensor-rich, indoor-exclusive dataset recorded in a controlled laboratory environment using a wheeled mobile robot platform. It includes four heterogeneous 3D LiDAR sensors \u2013 Velodyne VLP-16, Ouster OS1-64, RoboSense RS-Helios-5515, and Livox Mid-360 \u2013 featuring both mechanical spinning and non-repetitive scanning patterns, as well as an IMU and wheel odometry. The dataset also features calibration sequences, challenging benchmark trajectories, and high-precision ground-truth poses captured with a motion capture system. By combining diverse sensor technologies, extensive calibration data, and carefully designed indoor scenarios, IILABS 3D enables more comprehensive and reproducible evaluation of LiDAR-based SLAM algorithms, fostering innovation in autonomous navigation within complex indoor environments. The dataset information and associated tools are available on the project webpage: https://jorgedfr.github.io/3d_lidar_slam_benchmark_at_iilab.</p> <p>Keywords: dataset, ground mobile robot, indoor environment, Light Detection and Ranging (LiDAR), Simultaneous Localization and Mapping (SLAM).</p> <p>This repository hosts the complete documentation and supporting resources for the project \"Indoor Benchmark of 3D LiDAR SLAM at iilab - Industry and Innovation Laboratory\". The project evaluates state-of-the-art 3D LiDAR SLAM algorithms using data captured in indoor environments. To this end, the study introduces the novel IILABS\u00a03D dataset, which contains data from four diverse 3D LiDAR sensors (Velodyne VLP-16, Ouster OS1-64, RoboSense RS-Helios-5515, and Livox Mid-360), complemented by measurements from an IMU and wheel odometry.</p> <p>In parallel with the dataset, the project presents a detailed benchmark analysis of nine leading SLAM algorithms. By comparing algorithm-generated odometry against high-accuracy ground-truth data using metrics such as ATE, RTE, and RRE, the study provides valuable insights into the performance, limitations, and integration of these algorithms in indoor environments.</p> <p>The primary aim of this website and GitHub repository is to support researchers in developing, benchmarking, and applying 3D LiDAR-based SLAM solutions in indoor settings. As a result, the website includes the following information:</p> <ul> <li>Usage: Step-by-step instructions for replicating the benchmark study   using the provided scripts and dataset.</li> <li>Dataset: A detailed overview of the   IILABS\u00a03D dataset,   its structure, and key characteristics.</li> <li>Sensors: Specifications and technical details   of the sensors used during data collection.</li> <li>Benchmark: A summary of the benchmark scripts,   experimental setup, and key results from the analysis.</li> </ul> <p>Lastly, this work is within the scope of the Mobile Robotics Development Team (MRDT) in the national project GreenAuto: Green innovation for the Automotive Industry. MRDT team is a Research &amp; Development (R&amp;D) team from the CRIIS - Centre for Robotics in Industry and Intelligent Systems at the iilab - Industry and Innovation Laboratory.</p>"},{"location":"#videos","title":"Videos","text":"<ul> <li>How To Watch<ol> <li>Press the  Play button</li> <li>Use the  Previous and  Next    buttons to navigate through the playlist</li> </ol> </li> <li>Playlist YouTube Link: https://www.youtube.com/playlist?list=PL__T3ljZgf9tR-B4t1Kc1U7aTt-duUs-3</li> </ul>"},{"location":"#contacts","title":"Contacts","text":"<p>If you have any questions or you want to know more about this work, please contact one of the following contributors:</p> <ul> <li>Jorge Diogo Ribeiro   (jorge.d.ribeiro@inesctec.pt)   (Corresponding Author) ,   ,   ,   </li> <li>Ricardo B. Sousa   (rbs@fe.up.pt)   ,   ,   ,   </li> <li>Jo\u00e3o G. Martins   (joao.g.martins@inesctec.pt)   ,    </li> <li>Andr\u00e9 S. Aguiar   (andre.s.aguiar@inesctec.pt)   ,   ,   </li> <li>Filipe N. Santos   (filipe.n.santos@inesctec.pt)   ,   ,   </li> <li>H\u00e9ber Miguel Sobreira   (heber.m.sobreira@inesctec.pt)   ,   ,   </li> </ul>"},{"location":"#institutions","title":"Institutions","text":""},{"location":"#funding","title":"Funding","text":"<p>GreenAuto: Green innovation for the Automotive Industry</p> <ul> <li>Operation Code: 02/C05-i01.02/2022.PC644867037-00000013</li> <li>Beneficiary: Peugeot Citr\u00f6en Autom\u00f3veis Portugal, S.A.</li> <li>Work Package: WP10 - Automated logistics for the automotive industry</li> <li>Product, Processes, or Services (PPS):   PPS18 - 3D navigation system for mobile robotic equipment</li> <li>Consortium Partners:<ul> <li>Flowbotic Mobile Systems, Lda (leader)</li> <li>Faculty of Engineering, University of Porto (FEUP)</li> <li>INESC TEC - Institute for Systems and Computer Engineering, Technology and Science</li> <li>STAR</li> <li>Kaizen</li> <li>Institute for Systems and Robotics (ISR)-Coimbra</li> </ul> </li> <li>Timeline: October 2021 - December 2025</li> <li>Duration: 51 months</li> <li>URL: https://transparencia.gov.pt/en/fundos-europeus/prr/beneficiarios-projetos/projeto/02/C05-i01.02/2022.PC644867037-00000013/</li> </ul>"},{"location":"#citations","title":"Citations","text":""},{"location":"#article","title":"Article","text":"<p>TBC</p>"},{"location":"#dataset","title":"Dataset","text":"<p>Plain Text</p> <p>J.D. Ribeiro, R.B. Sousa, J.G. Martins, A.S. Aguiar, F.N. Santos and H.M. Sobreira, \"IILABS 3D: iilab Indoor LiDAR-based SLAM Dataset\", [Dataset], INESC TEC, 2025, doi: 10.25747/VHNJ-WM80.</p> <p>BibTex</p> <pre><code>@MISC{ribeiro:2025:iilabs3d:dataset,\n  author    = {J.D. Ribeiro and R.B. Sousa and J.G. Martins and A.S. Aguiar and F.N. Santos and H.M. Sobreira},\n  title     = {{IILABS 3D}: iilab {I}ndoor {LiDAR}-based {SLAM} {D}ataset},\n  year      = {2025},\n  publisher = {INESC TEC},\n  doi       = {10.25747/VHNJ-WM80},\n  note      = {[Dataset]},}\n</code></pre>"},{"location":"content/preprint/","title":"Preprint","text":""},{"location":"content/preprint/#documents","title":"Documents","text":"<ul> <li>pdf</li> <li>latex</li> </ul>"},{"location":"content/usage/","title":"Usage","text":"<p>The benchmark process involves the following steps:</p> <ol> <li>Download the IILABS 3D dataset</li> <li>Set up the Docker environment</li> <li>Run SLAM algorithms on the dataset</li> <li>Evaluate the results</li> </ol>"},{"location":"content/usage/#download-the-iilabs-3d-dataset","title":"Download the IILABS 3D Dataset","text":"<p>The IILABS 3D dataset is available at the INESC TEC research data repository. You can download it manually or use the IILABS 3D toolkit for easier access.</p>"},{"location":"content/usage/#using-the-iilabs-3d-toolkit","title":"Using the IILABS 3D Toolkit","text":"<p>The IILABS 3D Toolkit provides utilities for working with the dataset.</p>"},{"location":"content/usage/#installation","title":"Installation","text":"<pre><code>pip install iilabs3d-toolkit\n</code></pre> <p>Autocompletion</p> <p>You can install autocompletion for the toolkit by running: <pre><code>iilabs3d --install-completion\n</code></pre> Restart your shell for the autocompletion to take effect.</p>"},{"location":"content/usage/#downloading-sequences","title":"Downloading Sequences","text":"<p>To download a specific sequence for a specific sensor:</p> <pre><code>iilabs3d download &lt;output_directory&gt; &lt;sequence_name&gt; &lt;sensor_name&gt;\n</code></pre> <p>For example, to download the loop benchmark sequence for the Livox Mid-360 sensor:</p> <pre><code>iilabs3d download ~/slam_data loop livox_mid_360\n</code></pre> <p>To download all benchmark sequences for all sensors:</p> <pre><code>iilabs3d download ~/slam_data bench all\n</code></pre> <p>Dataset Structure</p> <p>The sequences will be saved in the following structure: <pre><code>&lt;output_directory&gt;/iilabs3d-dataset/&lt;sequence_prefix&gt;/&lt;sensor_name&gt;/&lt;sequence_name&gt;/\n</code></pre></p> <p>Dataset Directory</p> <p>The provided Docker Compose file is configured to mount the <code>${HOME}/slam_data</code> directory, allowing containerized access to the dataset files. To ensure proper functionality, save your dataset in this directory. Alternatively, you can modify the <code>docker-compose.yml</code> file to specify a different path if needed.</p>"},{"location":"content/usage/#set-up-the-docker-environment","title":"Set Up the Docker Environment","text":"<p>The benchmark uses Docker to ensure a consistent environment for all SLAM algorithms. This approach guarantees reproducibility and simplifies the setup process.</p>"},{"location":"content/usage/#prerequisites","title":"Prerequisites","text":"<ul> <li> Docker installed on your system</li> <li> At least 10GB of free disk space</li> <li> 16GB RAM recommended for optimal performance</li> </ul> <p>Guide for installing Docker and other tools in Ubuntu 20.04</p> <p>For more detailed information about the Docker installation and additional setups, please refer to the Install Docker section.</p>"},{"location":"content/usage/#clone-the-repository","title":"Clone the Repository","text":"<pre><code>git clone https://github.com/JorgeDFR/3d_lidar_slam_benchmark_at_iilab.git\ncd 3d_lidar_slam_benchmark_at_iilab/docker\n</code></pre>"},{"location":"content/usage/#build-and-run-docker-containers","title":"Build and Run Docker Containers","text":"<p>The benchmark uses two Docker images. You can either build the images locally from the provided Dockerfiles (slower, compiles libraries/packages) or pull prebuilt images from Docker Hub (faster).</p> ROS 1 (Noetic)ROS 2 (Humble) <p>Contains the following SLAM algorithms:</p> <ul> <li> A-LOAM</li> <li> LeGO-LOAM-BOR</li> <li> LIORF</li> <li> DLIO</li> </ul> <p>Contains the following SLAM algorithms:</p> <ul> <li> VineSLAM</li> <li> KISS-ICP</li> <li> GLIM</li> <li> Kinematic-ICP</li> <li> MOLA-LO</li> </ul> <p>GUI Applications</p> <p>Before running RViz inside the Docker container, you need to set up <code>xhost</code>: <pre><code>./setup_xhost.sh\n</code></pre></p>"},{"location":"content/usage/#option-1-pull-prebuilt-image","title":"Option 1: Pull Prebuilt Image","text":"<pre><code>docker pull jorgedfr/3d_slam_ros1:noetic\n</code></pre>"},{"location":"content/usage/#option-2-build-image-locally","title":"Option 2: Build Image Locally","text":"<pre><code>docker compose build ros1_noetic\n</code></pre>"},{"location":"content/usage/#start-docker-container","title":"Start Docker Container","text":"<pre><code>docker compose up ros1_noetic -d\n</code></pre>"},{"location":"content/usage/#access-docker-container","title":"Access Docker Container","text":"<pre><code>docker exec -it 3d_slam_ros1 bash\n</code></pre>"},{"location":"content/usage/#option-1-pull-prebuilt-image_1","title":"Option 1: Pull Prebuilt Image","text":"<pre><code>docker pull jorgedfr/3d_slam_ros2:humble\n</code></pre>"},{"location":"content/usage/#option-2-build-image-locally_1","title":"Option 2: Build Image Locally","text":"<pre><code>docker compose build ros2_humble\n</code></pre>"},{"location":"content/usage/#start-docker-container_1","title":"Start Docker Container","text":"<pre><code>docker compose up ros2_humble -d\n</code></pre>"},{"location":"content/usage/#access-docker-container_1","title":"Access Docker Container","text":"<pre><code>docker exec -it 3d_slam_ros2 bash\n</code></pre>"},{"location":"content/usage/#run-slam-algorithms-on-the-dataset","title":"Run SLAM Algorithms on the Dataset","text":"ROS 1 (Noetic)ROS 2 (Humble) <p>In one terminal, set the enviroment variables to select the algorithm and 3D LiDAR sensor, and start the SLAM algorithm:</p> <pre><code># Set environment variables\nexport SLAM_CONF=&lt;algorithm_name&gt;  \n# Options: aloam, lego_loam_bor, liorf, dlio\n\nexport SLAM_SENSOR=&lt;sensor_name&gt;  \n# Options: velodyne_vlp_16, ouster_os1_64, robosense_rs_helios_5515, livox_mid_360\n\n# Start the SLAM algorithm\nroslaunch slam_benchmark_ros1_conf slam_benchmark.launch\n</code></pre> <p>In another terminal, play the rosbag of the desired sequence:</p> <pre><code>rosbag play &lt;rosbag_file_path&gt;\n</code></pre> <p>In one terminal, set the enviroment variables to select the algorithm and 3D LiDAR sensor, and start the SLAM algorithm:</p> <p><pre><code># Set environment variables\nexport SLAM_CONF=&lt;algorithm_name&gt;  \n# Options: vineslam, kiss_icp, glim, kinematic_icp, mola_lo\n\nexport SLAM_SENSOR=&lt;sensor_name&gt;  \n# Options: velodyne_vlp_16, ouster_os1_64, robosense_rs_helios_5515, livox_mid_360\n\n# Start the SLAM algorithm\nros2 launch slam_benchmark_ros2_conf slam_benchmark.launch.xml\n</code></pre> In another terminal, play the rosbag of the desired sequence:</p> <pre><code>ros2 bag play &lt;rosbag_file_path&gt;\n</code></pre> <p>VineSLAM Special Case</p> <p>VineSLAM requires recompilation of its ROS 2 package whenever the LiDAR sensor is changed. Use the <code>-DLIDAR_TYPE</code> CMake argument to specify your sensor:</p> <ul> <li><code>-DLIDAR_TYPE=0</code> (default) for Velodyne VLP-16</li> <li><code>-DLIDAR_TYPE=1</code> for RoboSense RS-Helios-5515</li> <li><code>-DLIDAR_TYPE=3</code> for Ouster-OS1-64</li> <li><code>-DLIDAR_TYPE=4</code> for Livox Mid-360</li> </ul> <pre><code>cd ros2_ws\ncolcon build --packages-select vineslam_ros --cmake-args -DLIDAR_TYPE=0\n</code></pre>"},{"location":"content/usage/#offline-processing-mode","title":"Offline Processing Mode","text":"<p>Alternatively, several SLAM algorithms support an offline mode that processes rosbag files faster than real-time without losing messages:</p> ROS 1 (Noetic)ROS 2 (Humble) <pre><code>roslaunch slam_benchmark_ros1_conf slam_benchmark.launch run_offline:=true rosbag_path:=&lt;rosbag_file_path&gt;\n</code></pre> <pre><code>ros2 launch slam_benchmark_ros2_conf slam_benchmark.launch.xml run_offline:=true rosbag_path:=&lt;rosbag_file_path&gt;\n</code></pre> <p>Supported Algorithms for Offline Mode</p> <p>The following algorithms currently support offline processing:</p> <ul> <li>LeGO-LOAM-BOR</li> <li>GLIM</li> <li>Kinematic-ICP</li> <li>MOLA-LO</li> </ul>"},{"location":"content/usage/#record-and-evaluate-results","title":"Record and Evaluate Results","text":""},{"location":"content/usage/#recording-odometry-trajectories","title":"Recording Odometry Trajectories","text":"<p>To record the odometry trajectory generated by the SLAM algorithms, run the following command in another terminal:</p> ROS 1 (Noetic)ROS 2 (Humble) <pre><code>rosbag record -O &lt;output_bag_file_name&gt; /slam_odom\n</code></pre> <pre><code>ros2 bag record -o &lt;output_bag_file_name&gt; /slam_odom\n</code></pre> <p>MOLA-LO Special Case</p> <p>For MOLA-LO, set an environment variable to use the LiDAR frame instead of the default <code>base_link</code> frame. This step is necessary because MOLA-LO expects the robot frame to be <code>base_link</code>, while the IILABS 3D dataset uses <code>eve/base_link</code>. Then use the <code>mola-lidar-odometry-cli</code> command. For more informations regarding this tool please refer to the MOLA main documentation. <pre><code># Set environment variable to use the LiDAR frame instead of base_link\nexport MOLA_USE_FIXED_LIDAR_POSE=true\n\nmola-lidar-odometry-cli \\\n    -c $(ros2 pkg prefix mola_lidar_odometry)/share/mola_lidar_odometry/pipelines/lidar3d-default.yaml \\\n    --input-rosbag2 &lt;path_to_bag_file&gt; \\\n    --lidar-sensor-label &lt;lidar_topic&gt; \\\n    --output-tum-path &lt;output_file_path&gt;\n</code></pre></p> <ul> <li><code>&lt;path_to_bag_file&gt;</code>: Path to your input rosbag file</li> <li><code>&lt;lidar_topic&gt;</code>: LiDAR sensor topic name (<code>/eve/ouster/points</code> for Ouster sequences or <code>/eve/lidar3d</code> for other sensors)</li> <li><code>&lt;output_file_path&gt;</code>: Desired path for the TUM-formatted trajectory output</li> </ul>"},{"location":"content/usage/#converting-to-tum-format","title":"Converting to TUM Format","text":"<p>Now, to convert the odometry trajectory to TUM format, you can use the evo toolkit, which is automatically installed along with the IILABS 3D toolkit:</p> ROS 1 (Noetic)ROS 2 (Humble) <pre><code>evo_traj bag &lt;rosbag_file_path&gt; slam_odom --save_as_tum\n</code></pre> <pre><code>evo_traj bag2 &lt;rosbag_file_path&gt; slam_odom --save_as_tum\n</code></pre>"},{"location":"content/usage/#evaluating-trajectories","title":"Evaluating Trajectories","text":"<p>Use the IILABS 3D toolkit to evaluate the trajectory against the ground truth:</p> <pre><code>iilabs3d eval &lt;ground_truth.tum&gt; &lt;odometry.tum&gt;\n</code></pre> <p>This will calculate metrics including Absolute Trajectory Error (ATE), Relative Translational Error (RTE), and Relative Rotational Error (RRE).</p>"},{"location":"content/benchmark/","title":"Benchmark","text":"<p>This section presents the methodology, experimental protocols, and comparative results for the SLAM algorithms evaluated on our IILABS\u00a03D dataset. By combining state-of-the-art SLAM algorithms with rich sensor data, our benchmark provides insights on performance in the following accuracy metrics:</p> <ul> <li>Absolute Trajectory Error (ATE)</li> <li>Relative Translational Error (RTE)</li> <li>Relative Rotational Error (RRE)</li> </ul> <p>Our goal is to support researchers in understanding the trade-offs and strengths of different approaches in challenging indoor environments.</p>"},{"location":"content/benchmark/#slam-algorithms","title":"SLAM Algorithms","text":"<p>The SLAM algorithms page features a detailed comparison of the state-of-the-art SLAM methods considered in the benchmark analysis.  For each algorithm, you\u2019ll find:</p> <ul> <li>SLAM algorithm paper link;</li> <li>Open-source code repository link;</li> <li>Supported ROS version;</li> <li>Compatibility with the different 3D LiDARs configurations;</li> <li>Key features, such as IMU and/or wheel odometry sensor fusion support, and loop closure detection;</li> <li>The publication year for reference.</li> </ul>"},{"location":"content/benchmark/#results","title":"Results","text":"<p>The Results section presents both quantitative and qualitative assessments. Here you will find:</p> <ul> <li>ATE, RTE, and RRE metrics: Comparative tables showing performance across different sensor setups and experimental sequences.</li> <li>Trajectory Plots: Visualizations of the odometry trajectories for each sensor and algorithm.</li> </ul> <p>These detailed comparisons help identify the strengths and limitations of each SLAM approach under varied conditions.</p>"},{"location":"content/benchmark/#docker-environment","title":"Docker Environment","text":"<p>For reproducibility and ease of experimentation, our benchmark incorporates a Dockerized environment.  This section covers:</p> <ul> <li>The containerized setup and dependencies;</li> <li>Scripts and instructions to run the benchmark experiments;</li> <li>Tips for replicating the results on your own system.</li> </ul>"},{"location":"content/benchmark/#overview-navigation","title":"Overview &amp; Navigation","text":"<p>Our benchmark is organized to streamline your review:</p> <ul> <li>Begin with SLAM Algorithms to understand the methods and their individual attributes;</li> <li>Move to Results to explore the performance metrics and trajectory visualizations;</li> <li>Finally, review the Docker Environment to replicate or extend the experiments in your own setup.</li> </ul> <p>By navigating through these sections, you will gain an in-depth perspective on the performance of LiDAR-based SLAM in an indoor setting.</p>"},{"location":"content/benchmark/docker/","title":"Docker Environment","text":"<p>To ensure reproducibility and consistency in the benchmarking process, we provide a Docker environment that contains all the necessary dependencies and configurations for running the SLAM algorithms. This Docker environment allows researchers to easily replicate our benchmarking results and test their own algorithms under the same conditions.</p>"},{"location":"content/benchmark/docker/#docker-images","title":"Docker Images","text":"<p>The benchmark uses two Docker images:</p> ROS 1 ImageROS 2 Image <p>Contains the following SLAM algorithms:</p> <ul> <li> A-LOAM</li> <li> LeGO-LOAM-BOR</li> <li> LIORF</li> <li> DLIO</li> </ul> <p>Contains the following SLAM algorithms:</p> <ul> <li> VineSLAM</li> <li> KISS-ICP</li> <li> GLIM</li> <li> Kinematic-ICP</li> <li> MOLA-LO</li> </ul> <p>Both images include:</p> <ul> <li> Visualization tools including RViz</li> <li> All necessary dependencies and configurations</li> </ul>"},{"location":"content/benchmark/docker/#installation","title":"Installation","text":""},{"location":"content/benchmark/docker/#prerequisites","title":"Prerequisites","text":"<ul> <li> Docker installed on your system</li> <li> At least 10GB of free disk space</li> <li> 16GB RAM recommended for optimal performance</li> </ul> <p>Guide for installing Docker and other tools in Ubuntu 20.04</p> <p>For more detailed information about the Docker installation and additional setups, please refer to the Install Docker section.</p>"},{"location":"content/benchmark/docker/#setup-instructions","title":"Setup Instructions","text":"<p>Clone the repository:</p> <pre><code>git clone https://github.com/JorgeDFR/3d_lidar_slam_benchmark_at_iilab.git\ncd 3d_lidar_slam_benchmark_at_iilab/docker\n</code></pre> ROS 1 (Noetic)ROS 2 (Humble) <p>GUI Applications</p> <p>Before running RViz inside the Docker container, you need to set up <code>xhost</code>: <pre><code>./setup_xhost.sh\n</code></pre></p> <p>Dataset Directory</p> <p>The provided Docker Compose file is configured to mount the <code>${HOME}/slam_data</code> directory, allowing containerized access to the dataset files. To ensure proper functionality, save your dataset in this directory. Alternatively, you can modify the <code>docker-compose.yml</code> file to specify a different path if needed.</p>"},{"location":"content/benchmark/docker/#option-1-pull-prebuilt-image-faster","title":"Option 1: Pull Prebuilt Image (faster)","text":"<pre><code>docker pull jorgedfr/3d_slam_ros1:noetic\n</code></pre>"},{"location":"content/benchmark/docker/#option-2-build-image-locally-slower","title":"Option 2: Build Image Locally (slower)","text":"<pre><code>docker compose build ros1_noetic\n</code></pre> <p>Start the Docker container:</p> <pre><code>docker compose up ros1_noetic -d\n</code></pre> <p>Access the Docker container:</p> <pre><code>docker exec -it 3d_slam_ros1 bash\n</code></pre>"},{"location":"content/benchmark/docker/#option-1-pull-prebuilt-image-faster_1","title":"Option 1: Pull Prebuilt Image (faster)","text":"<pre><code>docker pull jorgedfr/3d_slam_ros2:humble\n</code></pre>"},{"location":"content/benchmark/docker/#option-2-build-image-locally-slower_1","title":"Option 2: Build Image Locally (slower)","text":"<pre><code>docker compose build ros2_humble\n</code></pre> <p>Start the Docker container:</p> <pre><code>docker compose up ros2_humble -d\n</code></pre> <p>Access the Docker container:</p> <pre><code>docker exec -it 3d_slam_ros2 bash\n</code></pre>"},{"location":"content/benchmark/docker/#running-slam-algorithms","title":"Running SLAM Algorithms","text":"ROS 1 (Noetic)ROS 2 (Humble) <p>In one terminal, set the enviroment variables to select the algorithm and 3D LiDAR sensor, and start the SLAM algorithm:</p> <pre><code># Set environment variables\nexport SLAM_CONF=&lt;algorithm_name&gt;  \n# Options: aloam, lego_loam_bor, liorf, dlio\n\nexport SLAM_SENSOR=&lt;sensor_name&gt;  \n# Options: velodyne_vlp_16, ouster_os1_64, robosense_rs_helios_5515, livox_mid_360\n\n# Start the SLAM algorithm\nroslaunch slam_benchmark_ros1_conf slam_benchmark.launch\n</code></pre> <p>In another terminal, play the rosbag of the desired sequence:</p> <pre><code>rosbag play &lt;rosbag_file_path&gt;\n</code></pre> <p>In one terminal, set the enviroment variables to select the algorithm and 3D LiDAR sensor, and start the SLAM algorithm:</p> <p><pre><code># Set environment variables\nexport SLAM_CONF=&lt;algorithm_name&gt;  \n# Options: vineslam, kiss_icp, glim, kinematic_icp, mola_lo\n\nexport SLAM_SENSOR=&lt;sensor_name&gt;  \n# Options: velodyne_vlp_16, ouster_os1_64, robosense_rs_helios_5515, livox_mid_360\n\n# Start the SLAM algorithm\nros2 launch slam_benchmark_ros2_conf slam_benchmark.launch.xml\n</code></pre> In another terminal, play the rosbag of the desired sequence:</p> <pre><code>ros2 bag play &lt;rosbag_file_path&gt;\n</code></pre> <p>VineSLAM Special Case</p> <p>VineSLAM requires recompilation of its ROS 2 package whenever the LiDAR sensor is changed. Use the <code>-DLIDAR_TYPE</code> CMake argument to specify your sensor:</p> <ul> <li><code>-DLIDAR_TYPE=0</code> (default) for Velodyne VLP-16</li> <li><code>-DLIDAR_TYPE=1</code> for RoboSense RS-Helios-5515</li> <li><code>-DLIDAR_TYPE=3</code> for Ouster-OS1-64</li> <li><code>-DLIDAR_TYPE=4</code> for Livox Mid-360</li> </ul> <pre><code>cd ros2_ws\ncolcon build --packages-select vineslam_ros --cmake-args -DLIDAR_TYPE=0\n</code></pre>"},{"location":"content/benchmark/docker/#offline-processing-mode","title":"Offline Processing Mode","text":"<p>Alternatively, several SLAM algorithms support an offline mode that processes rosbag files faster than real-time without losing messages:</p> ROS 1 (Noetic)ROS 2 (Humble) <pre><code>roslaunch slam_benchmark_ros1_conf slam_benchmark.launch run_offline:=true rosbag_path:=&lt;rosbag_file_path&gt;\n</code></pre> <pre><code>ros2 launch slam_benchmark_ros2_conf slam_benchmark.launch.xml run_offline:=true rosbag_path:=&lt;rosbag_file_path&gt;\n</code></pre> <p>Supported Algorithms for Offline Mode</p> <p>The following algorithms currently support offline processing:</p> <ul> <li>LeGO-LOAM-BOR</li> <li>GLIM</li> <li>Kinematic-ICP</li> <li>MOLA-LO</li> </ul>"},{"location":"content/benchmark/docker/#recording-odometry-trajectories","title":"Recording Odometry Trajectories","text":"<p>To record the odometry trajectory generated by the SLAM algorithms, run the following command in another terminal:</p> ROS 1 (Noetic)ROS 2 (Humble) <pre><code>rosbag record -O &lt;output_bag_file_name&gt; /slam_odom\n</code></pre> <pre><code>ros2 bag record -o &lt;output_bag_file_name&gt; /slam_odom\n</code></pre> <p>MOLA-LO Special Case</p> <p>For MOLA-LO, use the following command: <pre><code># Set environment variable to use the LiDAR frame instead of base_link\nexport MOLA_USE_FIXED_LIDAR_POSE=true\n\nmola-lidar-odometry-cli \\\n    -c $(ros2 pkg prefix mola_lidar_odometry)/share/mola_lidar_odometry/pipelines/lidar3d-default.yaml \\\n    --input-rosbag2 &lt;path_to_bag_file&gt; \\\n    --lidar-sensor-label &lt;lidar_topic&gt; \\\n    --output-tum-path &lt;output_file_path&gt;\n</code></pre></p> <ul> <li><code>&lt;path_to_bag_file&gt;</code>: Path to your input rosbag file</li> <li><code>&lt;lidar_topic&gt;</code>: LiDAR sensor topic name (<code>/eve/ouster/points</code> for Ouster sequences or <code>/eve/lidar3d</code> for other sensors)</li> <li><code>&lt;output_file_path&gt;</code>: Desired path for the TUM-formatted trajectory output</li> </ul>"},{"location":"content/benchmark/install_docker/","title":"Install Docker on Ubuntu","text":"<p>This guide provides step-by-step instructions for installing Docker on Ubuntu 20.04, including optional configurations for NVIDIA GPUs and Docker Compose Plugin installation.</p>"},{"location":"content/benchmark/install_docker/#install-docker","title":"Install Docker","text":"<p>Docker is an open-source platform used to automate the deployment, scaling, and management of applications within lightweight, portable containers. The installation of Docker on Ubuntu involves adding Docker's official repositories, installing Docker Engine, and configuring Docker to run on your system. This section will guide you through the installation process.</p> <ul> <li>Official documentation: Docker Engine Webpage</li> </ul>"},{"location":"content/benchmark/install_docker/#step-by-step-instructions","title":"Step-by-step instructions:","text":"<ol> <li> <p>Update the apt package index and install necessary dependencies:     <pre><code>sudo apt-get install -y ca-certificates curl lsb-release\n</code></pre></p> </li> <li> <p>Add Docker's official GPG key:     <pre><code>sudo install -m 0755 -d /etc/apt/keyrings\nsudo curl -fsSL https://download.docker.com/linux/ubuntu/gpg -o /etc/apt/keyrings/docker.asc\n</code></pre></p> </li> <li> <p>Make the key accessible by everyone:     <pre><code>sudo chmod a+r /etc/apt/keyrings/docker.asc\n</code></pre></p> </li> <li> <p>Add the Docker repository to your system's APT sources:     <pre><code>echo \\\n\"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.asc] https://download.docker.com/linux/ubuntu \\\n$(. /etc/os-release &amp;&amp; echo \"$VERSION_CODENAME\") stable\" | \\\nsudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null\n</code></pre></p> </li> <li> <p>Update the apt package index again     <pre><code>sudo apt-get update\n</code></pre></p> </li> <li> <p>Install Docker Engine, CLI, and other related packages:     <pre><code>sudo apt-get install -y docker-ce docker-ce-cli containerd.io docker-buildx-plugin docker-compose-plugin\n</code></pre></p> </li> </ol>"},{"location":"content/benchmark/install_docker/#post-installation-steps-optional","title":"Post-installation steps (Optional):","text":"<p>To allow running Docker commands without the need for <code>sudo</code> privileges, you must add your user to the <code>docker</code> group. This step simplifies the process, especially if you plan to work with Docker frequently (more details here).</p> <ol> <li> <p>Create the Docker group if it doesn't exist:     <pre><code>sudo groupadd docker\n</code></pre></p> </li> <li> <p>Add your user to the Docker group:     <pre><code>sudo usermod -aG docker $USER\n</code></pre></p> </li> </ol> <p>Log Out required</p> <p>You will need to log out and log back in for the changes to take effect, or you can reboot your machine.</p>"},{"location":"content/benchmark/install_docker/#install-nvidia-container-toolkit-optional","title":"Install NVIDIA Container Toolkit (Optional)","text":"<p>The NVIDIA Container Toolkit enables Docker to utilize NVIDIA GPUs for running GPU-accelerated workloads in containers. This is particularly useful when running graphical applications like ROS (Robot Operating System) with tools such as RViz, which require GPU resources for rendering 3D visualizations. By leveraging the NVIDIA Container Toolkit, you can ensure that the necessary GPU acceleration is available within Docker containers, enabling seamless performance for ROS packages that require graphical interfaces.</p> <ul> <li>Official documentation: NVIDIA Container Toolkit Webpage</li> </ul>"},{"location":"content/benchmark/install_docker/#step-by-step-instructions_1","title":"Step-by-step instructions:","text":"<ol> <li> <p>Verify that your NVIDIA GPU is working:     <pre><code>nvidia-smi\n</code></pre></p> </li> <li> <p>Add the NVIDIA container toolkit repository's GPG key:     <pre><code>curl -fsSL https://nvidia.github.io/libnvidia-container/gpgkey | sudo gpg --dearmor -o /usr/share/keyrings/nvidia-container-toolkit-keyring.gpg\n</code></pre></p> </li> <li> <p>Add the NVIDIA container toolkit repository:     <pre><code>curl -s -L https://nvidia.github.io/libnvidia-container/stable/deb/nvidia-container-toolkit.list | \\\n    sed 's#deb https://#deb [signed-by=/usr/share/keyrings/nvidia-container-toolkit-keyring.gpg] https://#g' | \\\n    sudo tee /etc/apt/sources.list.d/nvidia-container-toolkit.list\n</code></pre></p> </li> <li> <p>Install the NVIDIA container toolkit package:     <pre><code>sudo apt-get update &amp;&amp; sudo apt-get install -y nvidia-container-toolkit\n</code></pre></p> </li> <li> <p>Configure Docker to use NVIDIA runtime:     <pre><code>sudo nvidia-ctk runtime configure --runtime=docker\n</code></pre></p> </li> <li> <p>Restart Docker service:     <pre><code>sudo systemctl restart docker\n</code></pre></p> </li> </ol>"},{"location":"content/benchmark/install_docker/#gpu-container-configuration","title":"GPU container configuration:","text":"<p>Every time you restart your system, you'll need to configure the X server to allow Docker containers to access the display. Use the following commands: <pre><code>xhost +local:docker\n</code></pre></p> <p>DISPLAY enviroment variable</p> <p>Adjust the DISPLAY enviroment variable (<code>:0</code>, <code>:1</code>, etc.) depending on your system\u2019s display settings if it is not set.</p>"},{"location":"content/benchmark/install_docker/#install-docker-compose-plugin-optional","title":"Install Docker Compose Plugin (Optional)","text":"<p>Docker Compose is a tool designed to simplify the configuration and management of multi-container Docker applications. In the context of running ROS packages that require GPU support (such as those using RViz), Docker Compose can be used to easily define and configure the necessary containers in a <code>docker-compose.yml</code> file. This integration helps to simplify the process of setting up and managing containers that leverage the NVIDIA runtime, making it easier to configure GPU access and other dependencies needed for your ROS environment. The Docker Compose Plugin integrates directly with Docker, allowing you to orchestrate these containers with minimal configuration.</p> <ul> <li>Official documentation: Docker Compose Plugin Webpage</li> </ul>"},{"location":"content/benchmark/install_docker/#step-by-step-instructions_2","title":"Step-by-step instructions:","text":"<ol> <li>Install the Docker Compose plugin: <pre><code>sudo apt-get update &amp;&amp; apt-get install -y docker-compose-plugin\n</code></pre></li> </ol>"},{"location":"content/benchmark/slam_algorithms/","title":"SLAM Algorithms","text":"<p>The benchmark evaluates nine state-of-the-art 3D LiDAR-based SLAM algorithms:</p> <ol> <li>A-LOAM: An advanced implementation of LOAM (LiDAR Odometry and Mapping)</li> <li>LeGO-LOAM-BOR: A fork of LeGO-LOAM with good software engineering practices to make the code more readable and efficient</li> <li>LIORF: A fork of LIO-SAM which removes the feature extraction module and makes it easier to adapt other sensors</li> <li>DLIO: A lightweight LiDAR-Inertial Odometry (LIO) algorithm with a coarse-to-fine approach in constructing continuous-time trajectories for precise motion correction</li> <li>VineSLAM: A localization and mapping algorithm designed for challenging agricultural environments</li> <li>KISS-ICP: An LiDAR Odometry ICP pipeline with the KISS principle (Keep It Simple and Scalable)</li> <li>GLIM: An versatile and extensible range-based 3D mapping framework</li> <li>Kinematic-ICP: An LiDAR Odometry ICP pipeline with kinematic constraints for wheeled robots</li> <li>MOLA-LO: A modular optimization framework for localization and mapping using LiDAR Odometry (LO)</li> </ol> SLAM Algorithm Code Repository ROS Version VLP-16 OS1-64 RS-5515 Mid-360 IMU Wheel Odom Loop Closure Year LOAM A-LOAM Noetic (ROS 1) X X X - - - - 2014 LeGO-LOAM LeGO-LOAM-BOR Noetic (ROS 1) X X X - - - X 2018 LIO-SAM LIORF Noetic (ROS 1) X X X - X - X 2020 DLIO Official Noetic (ROS 1) X X X X X - - 2022 VineSLAM Official Humble (ROS 2) X X X X X X - 2022 KISS-ICP Official Humble (ROS 2) X X X X - - - 2023 GLIM Official Humble (ROS 2) X X X X X - X 2024 Kinematic-ICP Official Humble (ROS 2) X X X X - X - 2024 MOLA-LO Official Humble (ROS 2) X X X X - - - 2024"},{"location":"content/benchmark/results/","title":"Benchmark Results","text":"<p>In this section, we present an evaluation of the selected LiDAR-based SLAM algorithms' performance on the IILABS\u00a03D dataset.  All result pages include detailed tables with performance metrics as well as trajectory plots for each experimental sequence.</p> <p>Each result page offers both quantitative and qualitative results for different SLAM algorithm, 3D LiDAR sensor, and dataset sequence combinations:</p> <ul> <li>Performance Tables: Comparative accuracy metrics (ATE, RTE, RRE);</li> <li>Trajectory Plots: Visual representations of the odometry trajectories.</li> </ul>"},{"location":"content/benchmark/results/#approaches-to-explore-the-results","title":"Approaches to Explore the Results","text":"<p>There are two complementary perspectives for analysing the results:</p>"},{"location":"content/benchmark/results/#results-by-slam-algorithm","title":"Results by SLAM Algorithm","text":"<p>This view groups results by individual SLAM algorithms.  Each page details the performance obtained when using all sensor combinations with the selected algorithm.  Use this perspective to assess the impact of sensor inputs on a single SLAM method.</p> <ul> <li>A-LOAM</li> <li>LeGO-LOAM-BOR</li> <li>LIORF</li> <li>DLIO</li> <li>VineSLAM</li> <li>KISS-ICP</li> <li>GLIM</li> <li>Kinematic-ICP</li> <li>MOLA-LO</li> </ul>"},{"location":"content/benchmark/results/#results-by-3d-lidar-sensor","title":"Results by 3D LiDAR Sensor","text":"<p>This perspective organizes results by the specific 3D LiDAR sensor used in the experiments.  Each page presents the performance metrics and trajectory plots for all SLAM algorithms when using that particular sensor.  This approach highlights the influence of sensor characteristics, such as scanning pattern, resolution, and field-of-view, on overall SLAM performance.</p> <ul> <li>Livox Mid-360</li> <li>Ouster OS1-64</li> <li>RoboSense RS-Helios-5515</li> <li>Velodyne VLP-16</li> </ul> <p>Choose the perspective that best meets your exploration needs. Whether you're interested in the performance of a specific algorithm across all sensors or in understanding how a particular sensor affects SLAM performance across multiple algorithms, our benchmark results are designed to offer a clear and comprehensive analysis.</p>"},{"location":"content/benchmark/results/3d_lidar_sensors/livox_mid-360/","title":"Livox Mid-360","text":""},{"location":"content/benchmark/results/3d_lidar_sensors/livox_mid-360/#absolute-trajectory-error-ate","title":"Absolute Trajectory Error (ATE)","text":"<p>Root Mean Square Error (RMSE) of the absolute position differences. Values are presented in meters (m).</p> 3D LiDAR Sensor Nav A Diff Nav A Omni Loop Slippage Ramp A-LOAM - - - - - LeGO-LOAM-BOR - - - - - LIORF - - - - - DLIO 0.027 m 0.021 m 0.017 m 0.030 m 0.012 m VineSLAM 0.188 m 0.106 m 0.124 m 0.096 m 0.108 m KISS-ICP 0.031 m 0.030 m 0.026 m 0.033 m 0.028 m GLIM 0.017 m 0.016 m 0.104 m 0.025 m 0.057 m Kinematic-ICP 0.085 m 0.181 m 0.053 m 0.584 m - MOLA-LO 0.025 m 0.022 m 0.018 m 0.027 m 0.023 m"},{"location":"content/benchmark/results/3d_lidar_sensors/livox_mid-360/#relative-translational-error-rte","title":"Relative Translational Error (RTE)","text":"<p>Mean value calculated over all 10-meter segments. Values are presented as a percentage (%).</p> 3D LiDAR Sensor Nav A Diff Nav A Omni Loop Slippage Ramp A-LOAM - - - - - LeGO-LOAM-BOR - - - - - LIORF - - - - - DLIO 1.01% 0.99% 1.14% 0.92% 0.17% VineSLAM 2.70% 1.95% 2.07% 1.56% 1.12% KISS-ICP 0.76% 0.75% 0.83% 0.95% 0.53% GLIM 0.78% 0.81% 1.76% 0.82% 0.64% Kinematic-ICP 1.62% 2.31% 1.38% 7.45% - MOLA-LO 0.77% 0.77% 0.98% 0.93% 0.26%"},{"location":"content/benchmark/results/3d_lidar_sensors/livox_mid-360/#relative-rotational-error-rre","title":"Relative Rotational Error (RRE)","text":"<p>Mean value calculated over all 10-meter segments. Values are presented in degrees per meter (\u00b0/m).</p> 3D LiDAR Sensor Nav A Diff Nav A Omni Loop Slippage Ramp A-LOAM - - - - - LeGO-LOAM-BOR - - - - - LIORF - - - - - DLIO 0.056 \u00b0/m 0.069 \u00b0/m 0.050 \u00b0/m 0.042 \u00b0/m 0.073 \u00b0/m VineSLAM 0.223 \u00b0/m 0.188 \u00b0/m 0.146 \u00b0/m 0.072 \u00b0/m 0.335 \u00b0/m KISS-ICP 0.064 \u00b0/m 0.067 \u00b0/m 0.059 \u00b0/m 0.052 \u00b0/m 0.099 \u00b0/m GLIM 0.044 \u00b0/m 0.052 \u00b0/m 0.036 \u00b0/m 0.039 \u00b0/m 0.055 \u00b0/m Kinematic-ICP 0.066 \u00b0/m 0.108 \u00b0/m 0.084 \u00b0/m 0.106 \u00b0/m - MOLA-LO 0.057 \u00b0/m 0.063 \u00b0/m 0.058 \u00b0/m 0.047 \u00b0/m 0.056 \u00b0/m"},{"location":"content/benchmark/results/3d_lidar_sensors/livox_mid-360/#trajectory-plots","title":"Trajectory Plots","text":""},{"location":"content/benchmark/results/3d_lidar_sensors/livox_mid-360/#nav-a-diff-sequence","title":"Nav A Diff Sequence","text":""},{"location":"content/benchmark/results/3d_lidar_sensors/livox_mid-360/#nav-a-omni-sequence","title":"Nav A Omni Sequence","text":""},{"location":"content/benchmark/results/3d_lidar_sensors/livox_mid-360/#loop-sequence","title":"Loop Sequence","text":""},{"location":"content/benchmark/results/3d_lidar_sensors/livox_mid-360/#slippage-sequence","title":"Slippage Sequence","text":""},{"location":"content/benchmark/results/3d_lidar_sensors/livox_mid-360/#ramp-sequence","title":"Ramp Sequence","text":""},{"location":"content/benchmark/results/3d_lidar_sensors/livox_mid-360/#elevator-sequence","title":"Elevator Sequence","text":""},{"location":"content/benchmark/results/3d_lidar_sensors/ouster_os1-64/","title":"Ouster OS1-64","text":""},{"location":"content/benchmark/results/3d_lidar_sensors/ouster_os1-64/#absolute-trajectory-error-ate","title":"Absolute Trajectory Error (ATE)","text":"<p>Root Mean Square Error (RMSE) of the absolute position differences. Values are presented in meters (m).</p> 3D LiDAR Sensor Nav A Diff Nav A Omni Loop Slippage Ramp A-LOAM 0.039 m 0.043 m 0.029 m 0.041 m 0.038 m LeGO-LOAM-BOR 0.042 m 0.036 m 0.033 m 0.045 m 0.036 m LIORF 0.032 m 0.031 m 0.021 m 0.028 m 0.017 m DLIO 0.042 m 0.032 m 0.029 m 0.044 m 0.020 m VineSLAM 0.144 m 0.139 m 0.143 m 0.147 m 0.086 m KISS-ICP 0.036 m 0.038 m 0.032 m 0.035 m 0.030 m GLIM 0.029 m 0.021 m 0.034 m 0.036 m 0.053 m Kinematic-ICP 0.510 m 0.191 m 0.152 m 0.788 m - MOLA-LO 0.028 m 0.026 m 0.020 m 0.028 m 0.015 m"},{"location":"content/benchmark/results/3d_lidar_sensors/ouster_os1-64/#relative-translational-error-rte","title":"Relative Translational Error (RTE)","text":"<p>Mean value calculated over all 10-meter segments. Values are presented as a percentage (%).</p> 3D LiDAR Sensor Nav A Diff Nav A Omni Loop Slippage Ramp A-LOAM 1.11% 1.34% 1.15% 1.18% 0.39% LeGO-LOAM-BOR 1.14% 1.23% 1.43% 1.44% 0.52% LIORF 1.06% 1.24% 1.31% 1.19% 0.21% DLIO 1.40% 1.49% 1.41% 1.23% 0.19% VineSLAM 2.61% 2.86% 2.83% 2.57% 1.08% KISS-ICP 1.07% 1.10% 1.00% 1.12% 0.64% GLIM 1.15% 1.18% 1.17% 1.23% 0.34% Kinematic-ICP 3.18% 2.59% 1.95% 9.94% - MOLA-LO 0.97% 1.07% 1.06% 1.12% 0.24%"},{"location":"content/benchmark/results/3d_lidar_sensors/ouster_os1-64/#relative-rotational-error-rre","title":"Relative Rotational Error (RRE)","text":"<p>Mean value calculated over all 10-meter segments. Values are presented in degrees per meter (\u00b0/m).</p> 3D LiDAR Sensor Nav A Diff Nav A Omni Loop Slippage Ramp A-LOAM 0.072 \u00b0/m 0.089 \u00b0/m 0.080 \u00b0/m 0.088 \u00b0/m 0.052 \u00b0/m LeGO-LOAM-BOR 0.097 \u00b0/m 0.106 \u00b0/m 0.083 \u00b0/m 0.104 \u00b0/m 0.150 \u00b0/m LIORF 0.060 \u00b0/m 0.070 \u00b0/m 0.055 \u00b0/m 0.057 \u00b0/m 0.026 \u00b0/m DLIO 0.086 \u00b0/m 0.110 \u00b0/m 0.083 \u00b0/m 0.062 \u00b0/m 0.080 \u00b0/m VineSLAM 0.201 \u00b0/m 0.242 \u00b0/m 0.251 \u00b0/m 0.153 \u00b0/m 0.369 \u00b0/m KISS-ICP 0.073 \u00b0/m 0.079 \u00b0/m 0.063 \u00b0/m 0.069 \u00b0/m 0.087 \u00b0/m GLIM 0.066 \u00b0/m 0.075 \u00b0/m 0.058 \u00b0/m 0.074 \u00b0/m 0.050 \u00b0/m Kinematic-ICP 0.224 \u00b0/m 0.172 \u00b0/m 0.137 \u00b0/m 0.135 \u00b0/m - MOLA-LO 0.070 \u00b0/m 0.080 \u00b0/m 0.057 \u00b0/m 0.064 \u00b0/m 0.054 \u00b0/m"},{"location":"content/benchmark/results/3d_lidar_sensors/ouster_os1-64/#trajectory-plots","title":"Trajectory Plots","text":""},{"location":"content/benchmark/results/3d_lidar_sensors/ouster_os1-64/#nav-a-diff-sequence","title":"Nav A Diff Sequence","text":""},{"location":"content/benchmark/results/3d_lidar_sensors/ouster_os1-64/#nav-a-omni-sequence","title":"Nav A Omni Sequence","text":""},{"location":"content/benchmark/results/3d_lidar_sensors/ouster_os1-64/#loop-sequence","title":"Loop Sequence","text":""},{"location":"content/benchmark/results/3d_lidar_sensors/ouster_os1-64/#slippage-sequence","title":"Slippage Sequence","text":""},{"location":"content/benchmark/results/3d_lidar_sensors/ouster_os1-64/#ramp-sequence","title":"Ramp Sequence","text":""},{"location":"content/benchmark/results/3d_lidar_sensors/ouster_os1-64/#elevator-sequence","title":"Elevator Sequence","text":""},{"location":"content/benchmark/results/3d_lidar_sensors/robosense_rs-helios-5515/","title":"RoboSense RS-Helios-5515","text":""},{"location":"content/benchmark/results/3d_lidar_sensors/robosense_rs-helios-5515/#absolute-trajectory-error-ate","title":"Absolute Trajectory Error (ATE)","text":"<p>Root Mean Square Error (RMSE) of the absolute position differences. Values are presented in meters (m).</p> 3D LiDAR Sensor Nav A Diff Nav A Omni Loop Slippage Ramp A-LOAM 0.032 m 0.032 m 0.045 m 0.042 m 0.057 m LeGO-LOAM-BOR 0.040 m 0.038 m 0.039 m 0.043 m 0.041 m LIORF 0.029 m 0.024 m 0.023 m 0.029 m 0.034 m DLIO 0.068 m 0.050 m 0.040 m 0.074 m 0.030 m VineSLAM 0.108 m 0.078 m 0.123 m 0.095 m 0.056 m KISS-ICP 0.046 m 0.046 m 0.047 m 0.041 m 0.039 m GLIM 0.137 m 0.055 m 0.560 m 0.030 m 0.057 m Kinematic-ICP 0.337 m 0.178 m 0.103 m 0.676 m - MOLA-LO 0.044 m 0.031 m 0.032 m 0.040 m 0.134 m"},{"location":"content/benchmark/results/3d_lidar_sensors/robosense_rs-helios-5515/#relative-translational-error-rte","title":"Relative Translational Error (RTE)","text":"<p>Mean value calculated over all 10-meter segments. Values are presented as a percentage (%).</p> 3D LiDAR Sensor Nav A Diff Nav A Omni Loop Slippage Ramp A-LOAM 0.92% 1.05% 1.03% 1.32% 0.59% LeGO-LOAM-BOR 1.45% 1.29% 1.37% 1.71% 0.59% LIORF 1.23% 1.24% 1.28% 0.97% 0.47% DLIO 1.55% 1.64% 1.36% 1.31% 0.30% VineSLAM 2.00% 1.97% 2.55% 1.67% 0.80% KISS-ICP 1.10% 1.10% 1.00% 0.96% 0.58% GLIM 1.60% 1.16% 7.36% 1.43% 0.65% Kinematic-ICP 2.87% 2.27% 1.62% 8.86% - MOLA-LO 1.26% 1.15% 1.25% 1.21% 0.94%"},{"location":"content/benchmark/results/3d_lidar_sensors/robosense_rs-helios-5515/#relative-rotational-error-rre","title":"Relative Rotational Error (RRE)","text":"<p>Mean value calculated over all 10-meter segments. Values are presented in degrees per meter (\u00b0/m).</p> 3D LiDAR Sensor Nav A Diff Nav A Omni Loop Slippage Ramp A-LOAM 0.097 \u00b0/m 0.084 \u00b0/m 0.100 \u00b0/m 0.084 \u00b0/m 0.073 \u00b0/m LeGO-LOAM-BOR 0.114 \u00b0/m 0.104 \u00b0/m 0.132 \u00b0/m 0.114 \u00b0/m 0.168 \u00b0/m LIORF 0.090 \u00b0/m 0.109 \u00b0/m 0.093 \u00b0/m 0.077 \u00b0/m 0.119 \u00b0/m DLIO 0.107 \u00b0/m 0.122 \u00b0/m 0.102 \u00b0/m 0.073 \u00b0/m 0.125 \u00b0/m VineSLAM 0.148 \u00b0/m 0.177 \u00b0/m 0.199 \u00b0/m 0.111 \u00b0/m 0.315 \u00b0/m KISS-ICP 0.091 \u00b0/m 0.080 \u00b0/m 0.098 \u00b0/m 0.081 \u00b0/m 0.125 \u00b0/m GLIM 0.051 \u00b0/m 0.038 \u00b0/m 0.049 \u00b0/m 0.038 \u00b0/m 0.036 \u00b0/m Kinematic-ICP 0.184 \u00b0/m 0.143 \u00b0/m 0.118 \u00b0/m 0.110 \u00b0/m - MOLA-LO 0.104 \u00b0/m 0.076 \u00b0/m 0.104 \u00b0/m 0.099 \u00b0/m 0.230 \u00b0/m"},{"location":"content/benchmark/results/3d_lidar_sensors/robosense_rs-helios-5515/#trajectory-plots","title":"Trajectory Plots","text":""},{"location":"content/benchmark/results/3d_lidar_sensors/robosense_rs-helios-5515/#nav-a-diff-sequence","title":"Nav A Diff Sequence","text":""},{"location":"content/benchmark/results/3d_lidar_sensors/robosense_rs-helios-5515/#nav-a-omni-sequence","title":"Nav A Omni Sequence","text":""},{"location":"content/benchmark/results/3d_lidar_sensors/robosense_rs-helios-5515/#loop-sequence","title":"Loop Sequence","text":""},{"location":"content/benchmark/results/3d_lidar_sensors/robosense_rs-helios-5515/#slippage-sequence","title":"Slippage Sequence","text":""},{"location":"content/benchmark/results/3d_lidar_sensors/robosense_rs-helios-5515/#ramp-sequence","title":"Ramp Sequence","text":""},{"location":"content/benchmark/results/3d_lidar_sensors/robosense_rs-helios-5515/#elevator-sequence","title":"Elevator Sequence","text":""},{"location":"content/benchmark/results/3d_lidar_sensors/velodyne_vlp-16/","title":"Velodyne VLP-16","text":""},{"location":"content/benchmark/results/3d_lidar_sensors/velodyne_vlp-16/#absolute-trajectory-error-ate","title":"Absolute Trajectory Error (ATE)","text":"<p>Root Mean Square Error (RMSE) of the absolute position differences. Values are presented in meters (m).</p> 3D LiDAR Sensor Nav A Diff Nav A Omni Loop Slippage Ramp A-LOAM 0.031 m 0.049 m 0.039 m 0.040 m 0.031 m LeGO-LOAM-BOR 0.054 m 0.047 m 0.042 m 0.053 m 0.050 m LIORF 0.030 m 0.027 m 0.025 m 0.035 m 0.030 m DLIO 0.064 m 0.049 m 0.036 m 0.065 m 0.031 m VineSLAM 0.083 m 0.089 m 0.128 m 0.077 m 0.048 m KISS-ICP 0.052 m 0.047 m 0.045 m 0.045 m 0.041 m GLIM 0.525 m 0.286 m 1.563 m 0.082 m 0.068 m Kinematic-ICP 0.183 m 0.180 m 0.147 m 0.676 m - MOLA-LO 0.045 m 0.040 m 0.037 m 0.039 m 0.338 m"},{"location":"content/benchmark/results/3d_lidar_sensors/velodyne_vlp-16/#relative-translational-error-rte","title":"Relative Translational Error (RTE)","text":"<p>Mean value calculated over all 10-meter segments. Values are presented as a percentage (%).</p> 3D LiDAR Sensor Nav A Diff Nav A Omni Loop Slippage Ramp A-LOAM 1.28% 1.58% 1.68% 1.53% 0.38% LeGO-LOAM-BOR 1.33% 1.43% 1.67% 1.87% 0.75% LIORF 1.33% 1.43% 1.63% 1.40% 0.36% DLIO 1.77% 1.81% 1.69% 1.42% 0.30% VineSLAM 2.03% 2.00% 2.24% 2.18% 0.62% KISS-ICP 1.41% 1.38% 1.50% 1.56% 0.91% GLIM 2.99% 2.73% 18.69% 2.38% 0.82% Kinematic-ICP 2.43% 2.45% 1.96% 8.63% - MOLA-LO 1.41% 1.48% 1.69% 1.54% 3.53%"},{"location":"content/benchmark/results/3d_lidar_sensors/velodyne_vlp-16/#relative-rotational-error-rre","title":"Relative Rotational Error (RRE)","text":"<p>Mean value calculated over all 10-meter segments. Values are presented in degrees per meter (\u00b0/m).</p> 3D LiDAR Sensor Nav A Diff Nav A Omni Loop Slippage Ramp A-LOAM 0.066 \u00b0/m 0.084 \u00b0/m 0.104 \u00b0/m 0.083 \u00b0/m 0.072 \u00b0/m LeGO-LOAM-BOR 0.114 \u00b0/m 0.110 \u00b0/m 0.119 \u00b0/m 0.151 \u00b0/m 0.189 \u00b0/m LIORF 0.057 \u00b0/m 0.064 \u00b0/m 0.086 \u00b0/m 0.084 \u00b0/m 0.078 \u00b0/m DLIO 0.095 \u00b0/m 0.121 \u00b0/m 0.093 \u00b0/m 0.075 \u00b0/m 0.112 \u00b0/m VineSLAM 0.147 \u00b0/m 0.166 \u00b0/m 0.182 \u00b0/m 0.148 \u00b0/m 0.283 \u00b0/m KISS-ICP 0.093 \u00b0/m 0.091 \u00b0/m 0.096 \u00b0/m 0.088 \u00b0/m 0.149 \u00b0/m GLIM 0.048 \u00b0/m 0.046 \u00b0/m 0.083 \u00b0/m 0.036 \u00b0/m 0.040 \u00b0/m Kinematic-ICP 0.140 \u00b0/m 0.152 \u00b0/m 0.137 \u00b0/m 0.093 \u00b0/m - MOLA-LO 0.088 \u00b0/m 0.088 \u00b0/m 0.106 \u00b0/m 0.092 \u00b0/m 0.822 \u00b0/m"},{"location":"content/benchmark/results/3d_lidar_sensors/velodyne_vlp-16/#trajectory-plots","title":"Trajectory Plots","text":""},{"location":"content/benchmark/results/3d_lidar_sensors/velodyne_vlp-16/#nav-a-diff-sequence","title":"Nav A Diff Sequence","text":""},{"location":"content/benchmark/results/3d_lidar_sensors/velodyne_vlp-16/#nav-a-omni-sequence","title":"Nav A Omni Sequence","text":""},{"location":"content/benchmark/results/3d_lidar_sensors/velodyne_vlp-16/#loop-sequence","title":"Loop Sequence","text":""},{"location":"content/benchmark/results/3d_lidar_sensors/velodyne_vlp-16/#slippage-sequence","title":"Slippage Sequence","text":""},{"location":"content/benchmark/results/3d_lidar_sensors/velodyne_vlp-16/#ramp-sequence","title":"Ramp Sequence","text":""},{"location":"content/benchmark/results/3d_lidar_sensors/velodyne_vlp-16/#elevator-sequence","title":"Elevator Sequence","text":""},{"location":"content/benchmark/results/slam_algorithms/aloam/","title":"A-LOAM","text":""},{"location":"content/benchmark/results/slam_algorithms/aloam/#absolute-trajectory-error-ate","title":"Absolute Trajectory Error (ATE)","text":"<p>Root Mean Square Error (RMSE) of the absolute position differences. Values are presented in meters (m).</p> 3D LiDAR Sensor Nav A Diff Nav A Omni Loop Slippage Ramp Velodyne VLP-16 0.031 m 0.049 m 0.039 m 0.040 m 0.031 m Ouster OS1-64 0.039 m 0.043 m 0.029 m 0.041 m 0.038 m RoboSense RS-Helios-5515 0.032 m 0.032 m 0.045 m 0.042 m 0.057 m Livox Mid-360 - - - - -"},{"location":"content/benchmark/results/slam_algorithms/aloam/#relative-translational-error-rte","title":"Relative Translational Error (RTE)","text":"<p>Mean value calculated over all 10-meter segments. Values are presented as a percentage (%).</p> 3D LiDAR Sensor Nav A Diff Nav A Omni Loop Slippage Ramp Velodyne VLP-16 1.28% 1.58% 1.68% 1.53% 0.38% Ouster OS1-64 1.11% 1.34% 1.15% 1.18% 0.39% RoboSense RS-Helios-5515 0.92% 1.05% 1.03% 1.32% 0.59% Livox Mid-360 - - - - -"},{"location":"content/benchmark/results/slam_algorithms/aloam/#relative-rotational-error-rre","title":"Relative Rotational Error (RRE)","text":"<p>Mean value calculated over all 10-meter segments. Values are presented in degrees per meter (\u00b0/m).</p> 3D LiDAR Sensor Nav A Diff Nav A Omni Loop Slippage Ramp Velodyne VLP-16 0.066 \u00b0/m 0.084 \u00b0/m 0.104 \u00b0/m 0.083 \u00b0/m 0.072 \u00b0/m Ouster OS1-64 0.072 \u00b0/m 0.089 \u00b0/m 0.080 \u00b0/m 0.088 \u00b0/m 0.052 \u00b0/m RoboSense RS-Helios-5515 0.097 \u00b0/m 0.084 \u00b0/m 0.100 \u00b0/m 0.084 \u00b0/m 0.073 \u00b0/m Livox Mid-360 - - - - -"},{"location":"content/benchmark/results/slam_algorithms/aloam/#trajectory-plots","title":"Trajectory Plots","text":""},{"location":"content/benchmark/results/slam_algorithms/aloam/#nav-a-diff-sequence","title":"Nav A Diff Sequence","text":""},{"location":"content/benchmark/results/slam_algorithms/aloam/#nav-a-omni-sequence","title":"Nav A Omni Sequence","text":""},{"location":"content/benchmark/results/slam_algorithms/aloam/#loop-sequence","title":"Loop Sequence","text":""},{"location":"content/benchmark/results/slam_algorithms/aloam/#slippage-sequence","title":"Slippage Sequence","text":""},{"location":"content/benchmark/results/slam_algorithms/aloam/#ramp-sequence","title":"Ramp Sequence","text":""},{"location":"content/benchmark/results/slam_algorithms/aloam/#elevator-sequence","title":"Elevator Sequence","text":""},{"location":"content/benchmark/results/slam_algorithms/dlio/","title":"DLIO","text":""},{"location":"content/benchmark/results/slam_algorithms/dlio/#absolute-trajectory-error-ate","title":"Absolute Trajectory Error (ATE)","text":"<p>Root Mean Square Error (RMSE) of the absolute position differences. Values are presented in meters (m).</p> 3D LiDAR Sensor Nav A Diff Nav A Omni Loop Slippage Ramp Velodyne VLP-16 0.064 m 0.049 m 0.036 m 0.065 m 0.031 m Ouster OS1-64 0.042 m 0.032 m 0.029 m 0.044 m 0.020 m RoboSense RS-Helios-5515 0.068 m 0.050 m 0.040 m 0.074 m 0.030 m Livox Mid-360 0.027 m 0.021 m 0.017 m 0.030 m 0.012 m"},{"location":"content/benchmark/results/slam_algorithms/dlio/#relative-translational-error-rte","title":"Relative Translational Error (RTE)","text":"<p>Mean value calculated over all 10-meter segments. Values are presented as a percentage (%).</p> 3D LiDAR Sensor Nav A Diff Nav A Omni Loop Slippage Ramp Velodyne VLP-16 1.77% 1.81% 1.69% 1.42% 0.30% Ouster OS1-64 1.40% 1.49% 1.41% 1.23% 0.19% RoboSense RS-Helios-5515 1.55% 1.64% 1.36% 1.31% 0.30% Livox Mid-360 1.01% 0.99% 1.14% 0.92% 0.17%"},{"location":"content/benchmark/results/slam_algorithms/dlio/#relative-rotational-error-rre","title":"Relative Rotational Error (RRE)","text":"<p>Mean value calculated over all 10-meter segments. Values are presented in degrees per meter (\u00b0/m).</p> 3D LiDAR Sensor Nav A Diff Nav A Omni Loop Slippage Ramp Velodyne VLP-16 0.095 \u00b0/m 0.121 \u00b0/m 0.093 \u00b0/m 0.075 \u00b0/m 0.112 \u00b0/m Ouster OS1-64 0.086 \u00b0/m 0.110 \u00b0/m 0.083 \u00b0/m 0.062 \u00b0/m 0.080 \u00b0/m RoboSense RS-Helios-5515 0.107 \u00b0/m 0.122 \u00b0/m 0.102 \u00b0/m 0.073 \u00b0/m 0.125 \u00b0/m Livox Mid-360 0.056 \u00b0/m 0.069 \u00b0/m 0.050 \u00b0/m 0.042 \u00b0/m 0.073 \u00b0/m"},{"location":"content/benchmark/results/slam_algorithms/dlio/#trajectory-plots","title":"Trajectory Plots","text":""},{"location":"content/benchmark/results/slam_algorithms/dlio/#nav-a-diff-sequence","title":"Nav A Diff Sequence","text":""},{"location":"content/benchmark/results/slam_algorithms/dlio/#nav-a-omni-sequence","title":"Nav A Omni Sequence","text":""},{"location":"content/benchmark/results/slam_algorithms/dlio/#loop-sequence","title":"Loop Sequence","text":""},{"location":"content/benchmark/results/slam_algorithms/dlio/#slippage-sequence","title":"Slippage Sequence","text":""},{"location":"content/benchmark/results/slam_algorithms/dlio/#ramp-sequence","title":"Ramp Sequence","text":""},{"location":"content/benchmark/results/slam_algorithms/dlio/#elevator-sequence","title":"Elevator Sequence","text":""},{"location":"content/benchmark/results/slam_algorithms/glim/","title":"GLIM","text":""},{"location":"content/benchmark/results/slam_algorithms/glim/#absolute-trajectory-error-ate","title":"Absolute Trajectory Error (ATE)","text":"<p>Root Mean Square Error (RMSE) of the absolute position differences. Values are presented in meters (m).</p> 3D LiDAR Sensor Nav A Diff Nav A Omni Loop Slippage Ramp Velodyne VLP-16 0.525 m 0.286 m 1.563 m 0.082 m 0.068 m Ouster OS1-64 0.029 m 0.021 m 0.034 m 0.036 m 0.053 m RoboSense RS-Helios-5515 0.137 m 0.055 m 0.560 m 0.030 m 0.057 m Livox Mid-360 0.017 m 0.016 m 0.104 m 0.025 m 0.057 m"},{"location":"content/benchmark/results/slam_algorithms/glim/#relative-translational-error-rte","title":"Relative Translational Error (RTE)","text":"<p>Mean value calculated over all 10-meter segments. Values are presented as a percentage (%).</p> 3D LiDAR Sensor Nav A Diff Nav A Omni Loop Slippage Ramp Velodyne VLP-16 2.99% 2.73% 18.69% 2.38% 0.82% Ouster OS1-64 1.15% 1.18% 1.17% 1.23% 0.34% RoboSense RS-Helios-5515 1.60% 1.16% 7.36% 1.43% 0.65% Livox Mid-360 0.78% 0.81% 1.76% 0.82% 0.64%"},{"location":"content/benchmark/results/slam_algorithms/glim/#relative-rotational-error-rre","title":"Relative Rotational Error (RRE)","text":"<p>Mean value calculated over all 10-meter segments. Values are presented in degrees per meter (\u00b0/m).</p> 3D LiDAR Sensor Nav A Diff Nav A Omni Loop Slippage Ramp Velodyne VLP-16 0.048 \u00b0/m 0.046 \u00b0/m 0.083 \u00b0/m 0.036 \u00b0/m 0.040 \u00b0/m Ouster OS1-64 0.066 \u00b0/m 0.075 \u00b0/m 0.058 \u00b0/m 0.074 \u00b0/m 0.050 \u00b0/m RoboSense RS-Helios-5515 0.051 \u00b0/m 0.038 \u00b0/m 0.049 \u00b0/m 0.038 \u00b0/m 0.036 \u00b0/m Livox Mid-360 0.044 \u00b0/m 0.052 \u00b0/m 0.036 \u00b0/m 0.039 \u00b0/m 0.055 \u00b0/m"},{"location":"content/benchmark/results/slam_algorithms/glim/#trajectory-plots","title":"Trajectory Plots","text":""},{"location":"content/benchmark/results/slam_algorithms/glim/#nav-a-diff-sequence","title":"Nav A Diff Sequence","text":""},{"location":"content/benchmark/results/slam_algorithms/glim/#nav-a-omni-sequence","title":"Nav A Omni Sequence","text":""},{"location":"content/benchmark/results/slam_algorithms/glim/#loop-sequence","title":"Loop Sequence","text":""},{"location":"content/benchmark/results/slam_algorithms/glim/#slippage-sequence","title":"Slippage Sequence","text":""},{"location":"content/benchmark/results/slam_algorithms/glim/#ramp-sequence","title":"Ramp Sequence","text":""},{"location":"content/benchmark/results/slam_algorithms/glim/#elevator-sequence","title":"Elevator Sequence","text":""},{"location":"content/benchmark/results/slam_algorithms/kinematic_icp/","title":"Kinematic-ICP","text":""},{"location":"content/benchmark/results/slam_algorithms/kinematic_icp/#absolute-trajectory-error-ate","title":"Absolute Trajectory Error (ATE)","text":"<p>Root Mean Square Error (RMSE) of the absolute position differences. Values are presented in meters (m).</p> 3D LiDAR Sensor Nav A Diff Nav A Omni Loop Slippage Ramp Velodyne VLP-16 0.183 m 0.180 m 0.147 m 0.676 m - Ouster OS1-64 0.510 m 0.191 m 0.152 m 0.788 m - RoboSense RS-Helios-5515 0.337 m 0.178 m 0.103 m 0.676 m - Livox Mid-360 0.085 m 0.181 m 0.053 m 0.584 m -"},{"location":"content/benchmark/results/slam_algorithms/kinematic_icp/#relative-translational-error-rte","title":"Relative Translational Error (RTE)","text":"<p>Mean value calculated over all 10-meter segments. Values are presented as a percentage (%).</p> 3D LiDAR Sensor Nav A Diff Nav A Omni Loop Slippage Ramp Velodyne VLP-16 2.43% 2.45% 1.96% 8.63% - Ouster OS1-64 3.18% 2.59% 1.95% 9.94% - RoboSense RS-Helios-5515 2.87% 2.27% 1.62% 8.86% - Livox Mid-360 1.62% 2.31% 1.38% 7.45% -"},{"location":"content/benchmark/results/slam_algorithms/kinematic_icp/#relative-rotational-error-rre","title":"Relative Rotational Error (RRE)","text":"<p>Mean value calculated over all 10-meter segments. Values are presented in degrees per meter (\u00b0/m).</p> 3D LiDAR Sensor Nav A Diff Nav A Omni Loop Slippage Ramp Velodyne VLP-16 0.140 \u00b0/m 0.152 \u00b0/m 0.137 \u00b0/m 0.093 \u00b0/m - Ouster OS1-64 0.224 \u00b0/m 0.172 \u00b0/m 0.137 \u00b0/m 0.135 \u00b0/m - RoboSense RS-Helios-5515 0.184 \u00b0/m 0.143 \u00b0/m 0.118 \u00b0/m 0.110 \u00b0/m - Livox Mid-360 0.066 \u00b0/m 0.108 \u00b0/m 0.084 \u00b0/m 0.106 \u00b0/m -"},{"location":"content/benchmark/results/slam_algorithms/kinematic_icp/#trajectory-plots","title":"Trajectory Plots","text":""},{"location":"content/benchmark/results/slam_algorithms/kinematic_icp/#nav-a-diff-sequence","title":"Nav A Diff Sequence","text":""},{"location":"content/benchmark/results/slam_algorithms/kinematic_icp/#nav-a-omni-sequence","title":"Nav A Omni Sequence","text":""},{"location":"content/benchmark/results/slam_algorithms/kinematic_icp/#loop-sequence","title":"Loop Sequence","text":""},{"location":"content/benchmark/results/slam_algorithms/kinematic_icp/#slippage-sequence","title":"Slippage Sequence","text":""},{"location":"content/benchmark/results/slam_algorithms/kinematic_icp/#ramp-sequence","title":"Ramp Sequence","text":""},{"location":"content/benchmark/results/slam_algorithms/kinematic_icp/#elevator-sequence","title":"Elevator Sequence","text":""},{"location":"content/benchmark/results/slam_algorithms/kiss_icp/","title":"KISS-ICP","text":""},{"location":"content/benchmark/results/slam_algorithms/kiss_icp/#absolute-trajectory-error-ate","title":"Absolute Trajectory Error (ATE)","text":"<p>Root Mean Square Error (RMSE) of the absolute position differences. Values are presented in meters (m).</p> 3D LiDAR Sensor Nav A Diff Nav A Omni Loop Slippage Ramp Velodyne VLP-16 0.052 m 0.047 m 0.045 m 0.045 m 0.041 m Ouster OS1-64 0.036 m 0.038 m 0.032 m 0.035 m 0.030 m RoboSense RS-Helios-5515 0.046 m 0.046 m 0.047 m 0.041 m 0.039 m Livox Mid-360 0.031 m 0.030 m 0.026 m 0.033 m 0.028 m"},{"location":"content/benchmark/results/slam_algorithms/kiss_icp/#relative-translational-error-rte","title":"Relative Translational Error (RTE)","text":"<p>Mean value calculated over all 10-meter segments. Values are presented as a percentage (%).</p> 3D LiDAR Sensor Nav A Diff Nav A Omni Loop Slippage Ramp Velodyne VLP-16 1.41% 1.38% 1.50% 1.56% 0.91% Ouster OS1-64 1.07% 1.10% 1.00% 1.12% 0.64% RoboSense RS-Helios-5515 1.10% 1.10% 1.00% 0.96% 0.58% Livox Mid-360 0.76% 0.75% 0.83% 0.95% 0.53%"},{"location":"content/benchmark/results/slam_algorithms/kiss_icp/#relative-rotational-error-rre","title":"Relative Rotational Error (RRE)","text":"<p>Mean value calculated over all 10-meter segments. Values are presented in degrees per meter (\u00b0/m).</p> 3D LiDAR Sensor Nav A Diff Nav A Omni Loop Slippage Ramp Velodyne VLP-16 0.093 \u00b0/m 0.091 \u00b0/m 0.096 \u00b0/m 0.088 \u00b0/m 0.149 \u00b0/m Ouster OS1-64 0.073 \u00b0/m 0.079 \u00b0/m 0.063 \u00b0/m 0.069 \u00b0/m 0.087 \u00b0/m RoboSense RS-Helios-5515 0.091 \u00b0/m 0.080 \u00b0/m 0.098 \u00b0/m 0.081 \u00b0/m 0.125 \u00b0/m Livox Mid-360 0.064 \u00b0/m 0.067 \u00b0/m 0.059 \u00b0/m 0.052 \u00b0/m 0.099 \u00b0/m"},{"location":"content/benchmark/results/slam_algorithms/kiss_icp/#trajectory-plots","title":"Trajectory Plots","text":""},{"location":"content/benchmark/results/slam_algorithms/kiss_icp/#nav-a-diff-sequence","title":"Nav A Diff Sequence","text":""},{"location":"content/benchmark/results/slam_algorithms/kiss_icp/#nav-a-omni-sequence","title":"Nav A Omni Sequence","text":""},{"location":"content/benchmark/results/slam_algorithms/kiss_icp/#loop-sequence","title":"Loop Sequence","text":""},{"location":"content/benchmark/results/slam_algorithms/kiss_icp/#slippage-sequence","title":"Slippage Sequence","text":""},{"location":"content/benchmark/results/slam_algorithms/kiss_icp/#ramp-sequence","title":"Ramp Sequence","text":""},{"location":"content/benchmark/results/slam_algorithms/kiss_icp/#elevator-sequence","title":"Elevator Sequence","text":""},{"location":"content/benchmark/results/slam_algorithms/lego_loam_bor/","title":"LeGO-LOAM-BOR","text":""},{"location":"content/benchmark/results/slam_algorithms/lego_loam_bor/#absolute-trajectory-error-ate","title":"Absolute Trajectory Error (ATE)","text":"<p>Root Mean Square Error (RMSE) of the absolute position differences. Values are presented in meters (m).</p> 3D LiDAR Sensor Nav A Diff Nav A Omni Loop Slippage Ramp Velodyne VLP-16 0.054 m 0.047 m 0.042 m 0.053 m 0.050 m Ouster OS1-64 0.042 m 0.036 m 0.033 m 0.045 m 0.036 m RoboSense RS-Helios-5515 0.040 m 0.038 m 0.039 m 0.043 m 0.041 m Livox Mid-360 - - - - -"},{"location":"content/benchmark/results/slam_algorithms/lego_loam_bor/#relative-translational-error-rte","title":"Relative Translational Error (RTE)","text":"<p>Mean value calculated over all 10-meter segments. Values are presented as a percentage (%).</p> 3D LiDAR Sensor Nav A Diff Nav A Omni Loop Slippage Ramp Velodyne VLP-16 1.33% 1.43% 1.67% 1.87% 0.75% Ouster OS1-64 1.14% 1.23% 1.43% 1.44% 0.52% RoboSense RS-Helios-5515 1.45% 1.29% 1.37% 1.71% 0.59% Livox Mid-360 - - - - -"},{"location":"content/benchmark/results/slam_algorithms/lego_loam_bor/#relative-rotational-error-rre","title":"Relative Rotational Error (RRE)","text":"<p>Mean value calculated over all 10-meter segments. Values are presented in degrees per meter (\u00b0/m).</p> 3D LiDAR Sensor Nav A Diff Nav A Omni Loop Slippage Ramp Velodyne VLP-16 0.114 \u00b0/m 0.110 \u00b0/m 0.119 \u00b0/m 0.151 \u00b0/m 0.189 \u00b0/m Ouster OS1-64 0.097 \u00b0/m 0.106 \u00b0/m 0.083 \u00b0/m 0.104 \u00b0/m 0.150 \u00b0/m RoboSense RS-Helios-5515 0.114 \u00b0/m 0.104 \u00b0/m 0.132 \u00b0/m 0.114 \u00b0/m 0.168 \u00b0/m Livox Mid-360 - - - - -"},{"location":"content/benchmark/results/slam_algorithms/lego_loam_bor/#trajectory-plots","title":"Trajectory Plots","text":""},{"location":"content/benchmark/results/slam_algorithms/lego_loam_bor/#nav-a-diff-sequence","title":"Nav A Diff Sequence","text":""},{"location":"content/benchmark/results/slam_algorithms/lego_loam_bor/#nav-a-omni-sequence","title":"Nav A Omni Sequence","text":""},{"location":"content/benchmark/results/slam_algorithms/lego_loam_bor/#loop-sequence","title":"Loop Sequence","text":""},{"location":"content/benchmark/results/slam_algorithms/lego_loam_bor/#slippage-sequence","title":"Slippage Sequence","text":""},{"location":"content/benchmark/results/slam_algorithms/lego_loam_bor/#ramp-sequence","title":"Ramp Sequence","text":""},{"location":"content/benchmark/results/slam_algorithms/lego_loam_bor/#elevator-sequence","title":"Elevator Sequence","text":""},{"location":"content/benchmark/results/slam_algorithms/liorf/","title":"LIORF","text":""},{"location":"content/benchmark/results/slam_algorithms/liorf/#absolute-trajectory-error-ate","title":"Absolute Trajectory Error (ATE)","text":"<p>Root Mean Square Error (RMSE) of the absolute position differences. Values are presented in meters (m).</p> 3D LiDAR Sensor Nav A Diff Nav A Omni Loop Slippage Ramp Velodyne VLP-16 0.030 m 0.027 m 0.025 m 0.035 m 0.030 m Ouster OS1-64 0.032 m 0.031 m 0.021 m 0.028 m 0.017 m RoboSense RS-Helios-5515 0.029 m 0.024 m 0.023 m 0.029 m 0.034 m Livox Mid-360 - - - - -"},{"location":"content/benchmark/results/slam_algorithms/liorf/#relative-translational-error-rte","title":"Relative Translational Error (RTE)","text":"<p>Mean value calculated over all 10-meter segments. Values are presented as a percentage (%).</p> 3D LiDAR Sensor Nav A Diff Nav A Omni Loop Slippage Ramp Velodyne VLP-16 1.33% 1.43% 1.63% 1.40% 0.36% Ouster OS1-64 1.06% 1.24% 1.31% 1.19% 0.21% RoboSense RS-Helios-5515 1.23% 1.24% 1.28% 0.97% 0.47% Livox Mid-360 - - - - -"},{"location":"content/benchmark/results/slam_algorithms/liorf/#relative-rotational-error-rre","title":"Relative Rotational Error (RRE)","text":"<p>Mean value calculated over all 10-meter segments. Values are presented in degrees per meter (\u00b0/m).</p> 3D LiDAR Sensor Nav A Diff Nav A Omni Loop Slippage Ramp Velodyne VLP-16 0.057 \u00b0/m 0.064 \u00b0/m 0.086 \u00b0/m 0.084 \u00b0/m 0.078 \u00b0/m Ouster OS1-64 0.060 \u00b0/m 0.070 \u00b0/m 0.055 \u00b0/m 0.057 \u00b0/m 0.026 \u00b0/m RoboSense RS-Helios-5515 0.090 \u00b0/m 0.109 \u00b0/m 0.093 \u00b0/m 0.077 \u00b0/m 0.119 \u00b0/m Livox Mid-360 - - - - -"},{"location":"content/benchmark/results/slam_algorithms/liorf/#trajectory-plots","title":"Trajectory Plots","text":""},{"location":"content/benchmark/results/slam_algorithms/liorf/#nav-a-diff-sequence","title":"Nav A Diff Sequence","text":""},{"location":"content/benchmark/results/slam_algorithms/liorf/#nav-a-omni-sequence","title":"Nav A Omni Sequence","text":""},{"location":"content/benchmark/results/slam_algorithms/liorf/#loop-sequence","title":"Loop Sequence","text":""},{"location":"content/benchmark/results/slam_algorithms/liorf/#slippage-sequence","title":"Slippage Sequence","text":""},{"location":"content/benchmark/results/slam_algorithms/liorf/#ramp-sequence","title":"Ramp Sequence","text":""},{"location":"content/benchmark/results/slam_algorithms/liorf/#elevator-sequence","title":"Elevator Sequence","text":""},{"location":"content/benchmark/results/slam_algorithms/mola_lo/","title":"MOLA-LO","text":""},{"location":"content/benchmark/results/slam_algorithms/mola_lo/#absolute-trajectory-error-ate","title":"Absolute Trajectory Error (ATE)","text":"<p>Root Mean Square Error (RMSE) of the absolute position differences. Values are presented in meters (m).</p> 3D LiDAR Sensor Nav A Diff Nav A Omni Loop Slippage Ramp Velodyne VLP-16 0.045 m 0.040 m 0.037 m 0.039 m 0.338 m Ouster OS1-64 0.028 m 0.026 m 0.020 m 0.028 m 0.015 m RoboSense RS-Helios-5515 0.044 m 0.031 m 0.032 m 0.040 m 0.134 m Livox Mid-360 0.025 m 0.022 m 0.018 m 0.027 m 0.023 m"},{"location":"content/benchmark/results/slam_algorithms/mola_lo/#relative-translational-error-rte","title":"Relative Translational Error (RTE)","text":"<p>Mean value calculated over all 10-meter segments. Values are presented as a percentage (%).</p> 3D LiDAR Sensor Nav A Diff Nav A Omni Loop Slippage Ramp Velodyne VLP-16 1.41% 1.48% 1.69% 1.54% 3.53% Ouster OS1-64 0.97% 1.07% 1.06% 1.12% 0.24% RoboSense RS-Helios-5515 1.26% 1.15% 1.25% 1.21% 0.94% Livox Mid-360 0.77% 0.77% 0.98% 0.93% 0.26%"},{"location":"content/benchmark/results/slam_algorithms/mola_lo/#relative-rotational-error-rre","title":"Relative Rotational Error (RRE)","text":"<p>Mean value calculated over all 10-meter segments. Values are presented in degrees per meter (\u00b0/m).</p> 3D LiDAR Sensor Nav A Diff Nav A Omni Loop Slippage Ramp Velodyne VLP-16 0.088 \u00b0/m 0.088 \u00b0/m 0.106 \u00b0/m 0.092 \u00b0/m 0.822 \u00b0/m Ouster OS1-64 0.070 \u00b0/m 0.080 \u00b0/m 0.057 \u00b0/m 0.064 \u00b0/m 0.054 \u00b0/m RoboSense RS-Helios-5515 0.104 \u00b0/m 0.076 \u00b0/m 0.104 \u00b0/m 0.099 \u00b0/m 0.230 \u00b0/m Livox Mid-360 0.057 \u00b0/m 0.063 \u00b0/m 0.058 \u00b0/m 0.047 \u00b0/m 0.056 \u00b0/m"},{"location":"content/benchmark/results/slam_algorithms/mola_lo/#trajectory-plots","title":"Trajectory Plots","text":""},{"location":"content/benchmark/results/slam_algorithms/mola_lo/#nav-a-diff-sequence","title":"Nav A Diff Sequence","text":""},{"location":"content/benchmark/results/slam_algorithms/mola_lo/#nav-a-omni-sequence","title":"Nav A Omni Sequence","text":""},{"location":"content/benchmark/results/slam_algorithms/mola_lo/#loop-sequence","title":"Loop Sequence","text":""},{"location":"content/benchmark/results/slam_algorithms/mola_lo/#slippage-sequence","title":"Slippage Sequence","text":""},{"location":"content/benchmark/results/slam_algorithms/mola_lo/#ramp-sequence","title":"Ramp Sequence","text":""},{"location":"content/benchmark/results/slam_algorithms/mola_lo/#elevator-sequence","title":"Elevator Sequence","text":""},{"location":"content/benchmark/results/slam_algorithms/vineslam/","title":"VineSLAM","text":""},{"location":"content/benchmark/results/slam_algorithms/vineslam/#absolute-trajectory-error-ate","title":"Absolute Trajectory Error (ATE)","text":"<p>Root Mean Square Error (RMSE) of the absolute position differences. Values are presented in meters (m).</p> 3D LiDAR Sensor Nav A Diff Nav A Omni Loop Slippage Ramp Velodyne VLP-16 0.083 m 0.089 m 0.128 m 0.077 m 0.048 m Ouster OS1-64 0.144 m 0.139 m 0.143 m 0.147 m 0.086 m RoboSense RS-Helios-5515 0.108 m 0.078 m 0.123 m 0.095 m 0.056 m Livox Mid-360 0.188 m 0.106 m 0.124 m 0.096 m 0.108 m"},{"location":"content/benchmark/results/slam_algorithms/vineslam/#relative-translational-error-rte","title":"Relative Translational Error (RTE)","text":"<p>Mean value calculated over all 10-meter segments. Values are presented as a percentage (%).</p> 3D LiDAR Sensor Nav A Diff Nav A Omni Loop Slippage Ramp Velodyne VLP-16 2.03% 2.00% 2.24% 2.18% 0.62% Ouster OS1-64 2.61% 2.86% 2.83% 2.57% 1.08% RoboSense RS-Helios-5515 2.00% 1.97% 2.55% 1.67% 0.80% Livox Mid-360 2.70% 1.95% 2.07% 1.56% 1.12%"},{"location":"content/benchmark/results/slam_algorithms/vineslam/#relative-rotational-error-rre","title":"Relative Rotational Error (RRE)","text":"<p>Mean value calculated over all 10-meter segments. Values are presented in degrees per meter (\u00b0/m).</p> 3D LiDAR Sensor Nav A Diff Nav A Omni Loop Slippage Ramp Velodyne VLP-16 0.147 \u00b0/m 0.166 \u00b0/m 0.182 \u00b0/m 0.148 \u00b0/m 0.283 \u00b0/m Ouster OS1-64 0.201 \u00b0/m 0.242 \u00b0/m 0.251 \u00b0/m 0.153 \u00b0/m 0.369 \u00b0/m RoboSense RS-Helios-5515 0.148 \u00b0/m 0.177 \u00b0/m 0.199 \u00b0/m 0.111 \u00b0/m 0.315 \u00b0/m Livox Mid-360 0.223 \u00b0/m 0.188 \u00b0/m 0.146 \u00b0/m 0.072 \u00b0/m 0.335 \u00b0/m"},{"location":"content/benchmark/results/slam_algorithms/vineslam/#trajectory-plots","title":"Trajectory Plots","text":""},{"location":"content/benchmark/results/slam_algorithms/vineslam/#nav-a-diff-sequence","title":"Nav A Diff Sequence","text":""},{"location":"content/benchmark/results/slam_algorithms/vineslam/#nav-a-omni-sequence","title":"Nav A Omni Sequence","text":""},{"location":"content/benchmark/results/slam_algorithms/vineslam/#loop-sequence","title":"Loop Sequence","text":""},{"location":"content/benchmark/results/slam_algorithms/vineslam/#slippage-sequence","title":"Slippage Sequence","text":""},{"location":"content/benchmark/results/slam_algorithms/vineslam/#ramp-sequence","title":"Ramp Sequence","text":""},{"location":"content/benchmark/results/slam_algorithms/vineslam/#elevator-sequence","title":"Elevator Sequence","text":""},{"location":"content/dataset/","title":"Dataset","text":"<p>The IILABS 3D dataset was collected in the Industry and Innovation Laboratory. The dataset is composed by calibration and benchmark sequences. Each sequence contains data from multiple sensors, complemented by high-precision ground truth obtained via a Motion Capture (MoCap) system.</p> <p></p>"},{"location":"content/dataset/#key-features","title":"Key Features","text":"<ul> <li> Multiple 3D LiDAR Sensors: Data from four distinct 3D LiDAR sensors with different characteristics</li> <li> Additional Sensors: 2D LiDAR, IMU, and wheel odometry data</li> <li> Diverse Sequences: Both calibration sequences and challenging benchmark trajectories</li> <li> High-Precision Ground Truth: Sub-millimeter accuracy from a 24-camera OptiTrack system</li> </ul>"},{"location":"content/dataset/#sensors","title":"Sensors","text":"<p>The dataset includes data from the following sensors:</p>"},{"location":"content/dataset/#3d-lidars","title":"3D LiDARs","text":"<ul> <li>Livox Mid-360: Solid-state LiDAR with an non-repetitive scanning pattern</li> <li>Ouster OS1-64 RevC: 64-channel mechanical spinning LiDAR (45\u00b0 uniform vertical FoV)</li> <li>RoboSense RS-HELIOS-5515: 32-channel mechanical spinning LiDAR (70\u00b0 non-uniform vertical FoV)</li> <li>Velodyne VLP-16: 16-channel mechanical spinning LiDAR (30\u00b0 uniform vertical FoV)</li> </ul>"},{"location":"content/dataset/#additional-sensors","title":"Additional Sensors","text":"<ul> <li>Hokuyo UST-10LX: 2D LiDAR</li> <li>Xsens MTi-630 AHRS: Inertial Measurement Unit (IMU)</li> <li>Faulhaber 2342 wheel encoders: 64:1 gear ratio, 12 Counts Per Revolution (CPR)</li> </ul> <p>Sensor Details</p> <p>For detailed specifications of each sensor, please refer to the Sensors section.</p>"},{"location":"content/dataset/#data-formats","title":"Data Formats","text":"<p>The dataset provides three types of data:</p> <ol> <li> <p>Sensor Data: Provided in ROS 1 bag files, with each file representing a sequence during which the robot followed a defined trajectory.</p> </li> <li> <p>Ground Truth Data: Available as text files in TUM format (8 columns: timestamp in seconds, three columns for position coordinates, and four columns for orientation in quaternion format).</p> </li> <li> <p>Calibration Files: Supplied in YAML format, containing the calibration parameters for each sensor.</p> </li> </ol> <p>Convert dataset to ROS 2</p> <p>Even though the dataset is provided in ROS 1 bag files, we provide a way to convert to ROS 2 bag formats in our IILABS 3D toolkit.</p>"},{"location":"content/dataset/#ros-topics-and-explanation-of-each-message","title":"ROS Topics and Explanation of Each Message","text":"Topic Name Message Type Description Frequency /eve/lidar3d sensor_msgs/PointCloud2 raw pointcloud data (Velodyne VLP-16 / RoboSense RS-Helios-5515 / Livox Mid-360) 10Hz /eve/ouster/points sensor_msgs/PointCloud2 raw pointcloud data (Ouster OS1-64) 10Hz /eve/imu/data sensor_msgs/Imu raw IMU data (Xsens MTi-630) 400Hz /eve/ouster/imu sensor_msgs/Imu raw IMU data (Ouster OS1-64) 100Hz /eve/livox/imu sensor_msgs/Imu raw IMU data (Livox Mid-360) 200Hz /eve/scan sensor_msgs/LaserScan raw laser scan data (Hokuyo UST-10LX) 40Hz /eve/odom nav_msgs/Odometry wheel odometry processed data 100Hz /eve/motors_enc sdpo_drivers_interfaces/MotEncArrayROS1 raw motor encoders data 100Hz /eve/motors_ref sdpo_drivers_interfaces/MotRefArrayROS1 motor reference speeds - /tf tf2_msgs/TFMessage reference frame transformations - /tf_static tf2_msgs/TFMessage static reference frame transformations - <p>Custom ROS Messages</p> <p>The messages for the motor encoders data (<code>sdpo_drivers_interfaces/MotEncArrayROS1</code>) and motor reference speeds (<code>sdpo_drivers_interfaces/MotRefArrayROS1</code>) are custom ROS messages. These message definitions are included in this repository as a Git submodule via the 5dpo_drivers_interfaces package, which supports both ROS 1 and ROS 2. If you are cloning this repository, make sure to also initialize and update the submodules: <pre><code>git submodule update --init --recursive\n</code></pre> Moreover, when converting the dataset ROS bags to ROS 2 using the IILABS 3D Toolkit, the message type of these topics is automatically adjusted for the ROS 2 equivalent.</p>"},{"location":"content/dataset/#data-collection-method","title":"Data Collection Method","text":"Sensor Data CollectionGround Truth CollectionSynchronization <p>Sensor data was captured using the Robot Operating System (ROS) framework's rosbag record tool on a LattePanda 3 Delta embedded computer. Post-processing involved timestamp correction for the Xsens MTi-630 AHRS IMU via custom Python scripts.</p> <p>Ground-truth data was captured using an OptiTrack MoCap system featuring 24 high-resolution PrimeX 22 cameras. These cameras were connected via Ethernet to a primary Windows computer running the Motive software, which processed the camera data. This Windows computer was then connected via Ethernet to a secondary Ubuntu machine running the NatNet 4 ROS driver. The bag files were processed using the EVO open-source Python library to convert the data into TUM format and adjust the initial position offsets for accurate SLAM odometry benchmarking.</p> <p>Temporal synchronization between the robot platform and the ground-truth system was achieved using the Network Time Protocol (NTP). </p>"},{"location":"content/dataset/#accessing-the-dataset","title":"Accessing the Dataset","text":"<p>The IILABS 3D dataset is available at the INESC TEC research data repository. The dataset is approximately 350 GB in size.</p>"},{"location":"content/dataset/#using-the-iilabs-3d-toolkit","title":"Using the IILABS 3D Toolkit","text":"<p>The easiest way to access and work with the dataset is through the IILABS 3D Toolkit, a Python package that provides utilities for working with the dataset.</p> <pre><code># Install the toolkit\npip install iilabs3d-toolkit\n\n# List available sequences\niilabs3d list-sequences\n\n# List available sensors\niilabs3d list-sensors\n\n# Download a specific sequence for a specific sensor\niilabs3d download ~/slam_data loop livox_mid_360\n</code></pre> <p>Downloading All Data</p> <p>To download all benchmark sequences for all sensors: <pre><code>iilabs3d download ~/slam_data bench all\n</code></pre></p> <p>Additional Information</p> <p>For more information on using the toolkit, see the IILABS 3D Toolkit GitHub page.</p>"},{"location":"content/dataset/ground_truth/","title":"Ground Truth System","text":"<p>The ground truth data for the IILABS 3D dataset was captured using an OptiTrack Motion Capture (MoCap) system featuring 24 high-resolution PrimeX 22 cameras. This system was installed in Nav A, Floor 0 at the Industry and Innovation Laboratory.</p>"},{"location":"content/dataset/ground_truth/#overview","title":"Overview","text":""},{"location":"content/dataset/ground_truth/#system-components","title":"System Components","text":"<p>The OptiTrack system consists of the following components:</p> <ul> <li> 24 PrimeX 22 cameras mounted around the capture area</li> <li> Primary Windows computer running Motive software</li> <li> Secondary Ubuntu machine running the NatNet 4 ROS driver</li> <li> Network Time Protocol (NTP) for temporal synchronization</li> </ul>"},{"location":"content/dataset/ground_truth/#data-collection-process","title":"Data Collection Process","text":"<p>The ground truth data collection process involved several steps:</p> <ol> <li>The 24 PrimeX 22 cameras were connected via Ethernet to a primary Windows computer running the Motive software.</li> <li>The Motive software processed the camera data to track the position and orientation of the mobile robot.</li> <li>The Windows computer was connected via Ethernet to a secondary Ubuntu machine running the NatNet 4 ROS driver.</li> <li>The driver published the tracking data as ROS topics, which were recorded into rosbag files.</li> <li>Temporal synchronization between the robot platform and the ground-truth system was achieved using the Network Time Protocol (NTP).</li> </ol> <p>Post-Processing</p> <p>The bag files were processed using the EVO open-source Python library to convert the data into TUM format and adjust the initial position offsets for accurate SLAM odometry benchmarking.</p>"},{"location":"content/dataset/ground_truth/#ground-truth-data-format","title":"Ground Truth Data Format","text":"<p>The ground truth data is provided in TUM format, which is a standard format for trajectory data in robotics research. The TUM format consists of text files with each line containing:</p> <ul> <li>Timestamp (in seconds)</li> <li>Three columns for position coordinates (x, y, z)</li> <li>Four columns for orientation in quaternion format (qx, qy, qz, qw)</li> </ul> <pre><code># Example of ground truth data in TUM format\n1615554087.134 0.0123 -0.0456 0.0789 0.0012 0.0034 0.0056 0.9999\n</code></pre>"},{"location":"content/dataset/ground_truth/#reference-frame","title":"Reference Frame","text":"<p>The ground truth data is provided in the robot's <code>base_link</code> frame. This is important to note when comparing SLAM algorithm outputs with the ground truth, as the odometry data from SLAM algorithms may be in different reference frames (e.g., <code>base_footprint</code>, <code>imu</code>, or <code>lidar</code> frames).</p> <p>Reference Frame Correction</p> <p>The IILABS 3D toolkit provides a command to correct the reference frame of trajectory data: <pre><code>iilabs3d correct-frame &lt;trajectory.tum&gt; &lt;ref_frame&gt; [--sensor &lt;sensor_name&gt;]\n</code></pre></p>"},{"location":"content/dataset/ground_truth/#accuracy-and-precision","title":"Accuracy and Precision","text":"<p>The OptiTrack motion capture system provides highly accurate position and orientation measurements with:</p> <ul> <li>Sub-millimeter position accuracy</li> <li>Sub-degree orientation accuracy</li> </ul> <p>This high level of precision makes the ground truth data suitable for rigorous evaluation of SLAM algorithms, allowing researchers to accurately measure the performance of different algorithms in terms of trajectory accuracy and drift.</p>"},{"location":"content/dataset/ground_truth/#accessing-ground-truth-data","title":"Accessing Ground Truth Data","text":"<p>Ground truth data is included with each sequence in the dataset. When you download a sequence using the IILABS 3D toolkit, the ground truth data is provided as a <code>ground_truth.tum</code> file in the sequence directory:</p> <pre><code>&lt;save_directory&gt;/iilabs3d-dataset/&lt;sequence_prefix&gt;/&lt;sensor_name&gt;/&lt;sequence_name&gt;/ground_truth.tum\n</code></pre> <p>You can use this ground truth data to evaluate the performance of SLAM algorithms by comparing their estimated trajectories with the ground truth using the evaluation tools provided in the IILABS 3D toolkit.</p>"},{"location":"content/dataset/ground_truth/#gallery","title":"Gallery","text":""},{"location":"content/dataset/mobile_robot/","title":"Mobile Robot","text":"<p>The IILABS 3D dataset was collected using the INESC TEC MRDT Modified Hangfa Discovery Q2 Platform. This platform was specifically adapted for multi-sensor data collection in indoor environments, with a focus on 3D LiDAR-based SLAM research.</p> <p></p>"},{"location":"content/dataset/mobile_robot/#robot-specifications","title":"Robot Specifications","text":""},{"location":"content/dataset/mobile_robot/#base-platform","title":"Base Platform","text":"<p>The base platform is a modified Hangfa Discovery Q2, which has been customized by the INESC TEC Mobile Robot Dream Team (MRDT) to accommodate multiple sensors and provide a stable platform for data collection.</p>"},{"location":"content/dataset/mobile_robot/#dimensions","title":"Dimensions","text":"<ul> <li>Length: 500 mm</li> <li>Width: 400 mm</li> <li>Height: 600 mm (including sensor mounts)</li> </ul>"},{"location":"content/dataset/mobile_robot/#locomotion-system","title":"Locomotion System","text":"<ul> <li> Drive Type: Omnidirectional drive (Mecanum wheels)</li> <li> Motors: 4 \u00d7 Faulhaber 2342 DC motors</li> <li> Gear Ratio: 64:1</li> <li> Wheel Encoders: 12 Counts Per Revolution (CPR)</li> <li> Maximum Speed: 0.65 m/s</li> </ul>"},{"location":"content/dataset/mobile_robot/#power-system","title":"Power System","text":"<ul> <li> Battery: 24V LiPo battery</li> <li> Capacity: 10 Ah</li> <li> Runtime: Approximately 3 hours of continuous operation</li> </ul>"},{"location":"content/dataset/mobile_robot/#computing-system","title":"Computing System","text":"<ul> <li> Onboard Computer: LattePanda 3 Delta embedded computer</li> <li> Processor: Intel N100 (4 cores, 4 threads)</li> <li> RAM: 16 GB</li> <li> Storage: 512 GB SSD</li> <li> Operating System: Ubuntu 20.04 with ROS Noetic</li> </ul>"},{"location":"content/dataset/mobile_robot/#sensor-configuration","title":"Sensor Configuration","text":"<p>The mobile robot is equipped with multiple sensors to provide comprehensive data for SLAM benchmark:</p>"},{"location":"content/dataset/mobile_robot/#3d-lidars","title":"3D LiDARs","text":"Livox Mid-360Ouster OS1-64RoboSense RS-Helios-5515Velodyne VLP-16 <ul> <li>Field of View: 360\u00b0 horizontal, 59\u00b0 vertical</li> <li>Vertical Type: non-repetitive</li> <li>Range: 70m</li> <li>Rate: 10Hz</li> <li>Points per Second: ~200,000</li> </ul> <ul> <li>Field of View: 360\u00b0 horizontal, 45\u00b0 vertical</li> <li>Vertical Type: rotational uniform</li> <li>Range: 120m</li> <li>Rate: 10Hz</li> <li>Points per Second: ~1,310,720</li> </ul> <ul> <li>Field of View: 360\u00b0 horizontal, 70\u00b0 vertical</li> <li>Vertical Type: rotational non-uniform </li> <li>Range: 150m</li> <li>Rate: 10Hz</li> <li>Points per Second: ~1,152,000</li> </ul> <ul> <li>Field of View: 360\u00b0 horizontal, 30\u00b0 vertical</li> <li>Vertical Type: rotational uniform</li> <li>Range: 100m</li> <li>Rate: 10Hz</li> <li>Points per Second: ~288,000</li> </ul>"},{"location":"content/dataset/mobile_robot/#2d-lidar","title":"2D LiDAR","text":"Hokuyo UST-10LX-H01 <ul> <li>Field of View: 270\u00b0 </li> <li>Type: Time of Flight (ToF)</li> <li>Range: 10m</li> <li>Rate: 40Hz</li> <li>Points per Second: ~86,400</li> </ul>"},{"location":"content/dataset/mobile_robot/#inertial-measurement-unit-imu","title":"Inertial Measurement Unit (IMU)","text":"Xsens MTi-630 AHRS <ul> <li>Attitude Accuracy (Roll): 0.2\u00b0 (RMS)</li> <li>Attitude Accuracy (Pitch): 0.2\u00b0 (RMS)</li> <li>Attitude Accuracy (Yaw): 1\u00b0 (RMS)</li> <li>Rate: 400Hz</li> </ul> <p>Additional Information</p> <p>For more detailed information about the sensor specifications, please refer to the Sensors section.</p>"},{"location":"content/dataset/mobile_robot/#reference-frames","title":"Reference Frames","text":"<p>The robot uses the following reference frames:</p> <ul> <li>base_link: The main reference frame, located at the center of the robot wheels</li> <li>base_footprint: Located directly below base_link, on the ground plane</li> <li>lidar3d: Located at the center of each 3D LiDAR sensor</li> <li>laser: Located at the center of the 2D LiDAR sensor</li> <li>imu_link: Located at the center of the IMU</li> </ul> <p>Transformations</p> <p>The transformations between these reference frames are provided both in the tf topic in the rosbag files and in the calibration files included with the dataset. The transformations provided were calculated using the distances specified in the Computer Aided Design (CAD) 3D models.</p> <p>Robot Namespae</p> <p>All the reference frames are inside the mobile robot namespace eve. As such, in the rosbags files, the tf reference frames have this namespace as a prefix (e.g., eve/base_link).</p>"},{"location":"content/dataset/mobile_robot/#gallery","title":"Gallery","text":""},{"location":"content/dataset/sequences/benchmark_sequences/","title":"Benchmark Sequences","text":"<p>Benchmark sequences are designed to challenge SLAM algorithms with realistic indoor navigation scenarios. They serve several important purposes:</p> <ul> <li> Performance Evaluation: Evaluate algorithms in challenging real-world conditions</li> <li> Algorithm Comparison: Compare different algorithms under identical conditions</li> <li> Robustness Testing: Test algorithm resilience against various challenges</li> <li> Research Advancement: Identify strengths and weaknesses of current approaches</li> </ul> <p>The IILABS 3D dataset includes the following benchmark sequences:</p>"},{"location":"content/dataset/sequences/benchmark_sequences/#nav-a-diff","title":"Nav A Diff","text":"<p>Description: A trajectory with a loop arround the Nav A space of the iilab.</p> <p>Purpose: This sequence serves as a baseline, capturing typical environmental conditions without additional challenges.</p> <p>Challenge(s): No specific challenge</p> <p>Number of Cycle(s): 5 cycles</p> <p>Length: Approximately 275 meters</p> <p>Duration: Approximately 13 minutes</p>"},{"location":"content/dataset/sequences/benchmark_sequences/#nav-a-omni","title":"Nav A Omni","text":"<p>Description: </p> <p>Purpose: This sequence tests the algorithm's ability to handle complex movement patterns with decoupled translational and rotational planar motions of an omnidirectional steering platform.</p> <p>Challenge(s): Omnidirectional movement</p> <p>Number of Cycle(s): 2 cycles</p> <p>Length: Approximately 112 meters</p> <p>Duration: Approximately 7 minutes</p>"},{"location":"content/dataset/sequences/benchmark_sequences/#loop","title":"Loop","text":"<p>Description: A trajectory that includes a large loop around the main area of the iilab, where the robot exits and re-enters the Nav A space via different doors, briefly traversing an external corridor.</p> <p>Purpose: This sequence tests the algorithm's loop closure capabilities and global consistency.</p> <p>Challenge(s): Loop closure, sudden environmental changes (traversing doors)</p> <p>Number of Cycle(s): 5 cycles</p> <p>Length: Approximately 232 meters</p> <p>Duration: Approximately 11 minutes</p> <p>Ground Truth Data</p> <p>In the loop sequence, the mobile robot temporarily exists in the Nav A space and enters the external corridor. Since the ground-truth system is installed in the Nav A space, ground-truth data is only provided when the robot is inside the Nav A.</p>"},{"location":"content/dataset/sequences/benchmark_sequences/#slippage","title":"Slippage","text":"<p>Description: A trajectory involving a straight-line path where the robot executes high-speed lateral motions to intentionally induce wheel slippage.</p> <p>Purpose: This sequence tests the algorithm's robustness to wheel odometry drift caused by wheel slippage.</p> <p>Challenge(s): Wheel slippage, wheel odometry drift, wheel odometry errors</p> <p>Number of Cycle(s): 1 cycle</p> <p>Length: Approximately 39 meters</p> <p>Duration: Approximately 2 minutes</p>"},{"location":"content/dataset/sequences/benchmark_sequences/#ramp","title":"Ramp","text":"<p>Description: A trajectory that includes navigating up and down a ramp.</p> <p>Purpose: This sequence tests the algorithm's ability to handle elevation changes and maintain accurate pose estimation during inclines and declines.</p> <p>Challenge(s): Elevation changes, pitch rotations</p> <p>Number of Cycle(s): 3 cycles</p> <p>Length: Approximately 29 meters</p> <p>Duration: Approximately 3 minutes</p> <p>Mobile Robot Control</p> <p>In the ramp sequence, the mobile robot was controlled via a joystick, differently from the remaining sequences where a 2D navigation stack was used instead.</p>"},{"location":"content/dataset/sequences/benchmark_sequences/#elevator","title":"Elevator","text":"<p>Description: A trajectory that envolves an elevator to move from floor 0 and 1, with a period of time inside the closed elevator.</p> <p>Purpose: This sequence tests the algorithm's robustness to sudden changes in the environment and ability to recover from temporary loss of features. Moreover it also tests the algorithm's ability to accurately perform sensor fusion (e.g., using IMU data) for vertical motion estimations.</p> <p>Challenge(s): Sudden environment changes, feature loss, recovery, vertical motion</p> <p>Number of Cycle(s): 1 cycle</p> <p>Length: Approximately 85 meters</p> <p>Duration: Approximately 7 minutes</p> <p>Ground Truth Data</p> <p>In the elevator sequence, the mobile robot temporarily exists in the Nav A space and enters the external corridor, in order to access the elevator and move to the second floor. Since the ground-truth system is installed in the Nav A space, ground-truth data is only provided when the robot is inside the Nav A.</p>"},{"location":"content/dataset/sequences/benchmark_sequences/#accessing-benchmark-sequences","title":"Accessing Benchmark Sequences","text":"<p>You can download benchmark sequences using the IILABS 3D toolkit:</p> <pre><code>iilabs3d download &lt;output_directory&gt; &lt;sequence_name&gt; &lt;sensor_name&gt;\n</code></pre> <p>For example, to download the loop benchmark sequence for the Livox Mid-360 sensor:</p> <pre><code>iilabs3d download ~/slam_data loop livox_mid_360\n</code></pre> <p>Downloading All Benchmark Sequences</p> <p>To download all benchmark sequences for all sensors: <pre><code>iilabs3d download ~/slam_data bench all\n</code></pre></p>"},{"location":"content/dataset/sequences/calibration_sequences/","title":"Calibration Sequences","text":"<p>Calibration sequences are specifically designed to validate and optimize the calibration parameters provided with the dataset. As such they serve the following purposes:</p> <ul> <li> Validation: Verify the accuracy of the provided calibration parameters</li> <li> Optimization: Provide data for researchers to derive more optimal calibration parameters</li> </ul> <p>Calibration Parameters</p> <p>The IILABS 3D dataset includes pre-calibrated parameters in YAML format for all sensors. These calibration sequences provide a way to validate these parameters or derive new ones if needed.</p>"},{"location":"content/dataset/sequences/calibration_sequences/#imu-intrinsic-calibration","title":"IMU Intrinsic Calibration","text":"<p>To characterize each IMU's noise and bias behaviour, we recorded a three-hour stationary sequence for each of the following sensors:</p> <ul> <li>Xsens MTi-630 AHRS (external IMU)  </li> <li>Ouster OS1-64 (internal IMU)  </li> <li>Livox Mid-360 (internal IMU)  </li> </ul> <p>From these recordings, Allan-variance plots can be generated to estimate the noise and bias of both the gyroscope and accelerometer. In our benchmark, we used the Allan Variance ROS package to estimate these values and provide them in the YAML calibration files. For illustrative purposes, the following figures represent the Allan-variance plots obtained for the Xsens MTi-630 AHRS IMU.</p> <p></p> <p></p> <p>Parameter Adjustment</p> <p>To ensure a safe margin in the benchmark study, the YAML file values were inflated \u2013 bias values by a factor of 10 and white noise values by a factor of 5.</p>"},{"location":"content/dataset/sequences/calibration_sequences/#extrinsic-calibration-lidar-imu","title":"Extrinsic Calibration (LiDAR \u2013 IMU)","text":"<p>To determine the rigid\u2010body transform between each 3D LiDAR and the IMU, we recorded two complementary sequences:</p>"},{"location":"content/dataset/sequences/calibration_sequences/#full-excite-sequence","title":"Full Excite Sequence","text":"<ul> <li>Setup: Robot suspended in free space  </li> <li>Motion: Continuous rotations about the z-axis plus oscillations along the x- and y-axes  </li> <li>Use case: Ideal for six-degree-of-freedom IMU\u2013LiDAR solvers requiring full-axis excitation (e.g., LI-Init)</li> </ul> <p>Illustration</p> <p>Example GIF sourced from the LI-Init GitHub repository to demonstrate the excitation pattern. Actual dataset sequence uses the same motion profile for calibration.</p>"},{"location":"content/dataset/sequences/calibration_sequences/#infinity-sequence-lemniscate-of-bernoulli","title":"Infinity Sequence (Lemniscate of Bernoulli)","text":"<ul> <li>Path: Floor-level figure-eight (lemniscate) trajectory  </li> <li>Equation:  \\(     x(t) = \\frac{a\\cos t}{1 + \\sin^2 t},      \\quad     y(t) = \\frac{a\\sin t\\cos t}{1 + \\sin^2 t},     \\quad a = c\\sqrt{2},     \\quad PF_1 \\cdot PF_2 = c^2     \\)</li> <li>Use case: Suited for ground-robot calibration algorithms exploiting planar constraints (e.g., GRIL-Calib)</li> </ul>"},{"location":"content/dataset/sequences/calibration_sequences/#wheel-odometry-calibration","title":"Wheel Odometry Calibration","text":"<p>The dataset includes wheel odometry calibration sequences that consist of 2m\u00d72m square-shaped trajectories, a widely used approach for odometry calibration in mobile robotics.</p> <p></p> <p>Four distinct trajectory patterns were executed:</p> Pattern Description Cycles Length Duration CW with Rotation Clockwise square, rotate in place at each corner 2 ~16 m ~2 min CW without Rotation Clockwise square, pure 90\u00b0 turns 2 ~16 m ~1 min CCW with Rotation Counterclockwise square, rotate at each corner 2 ~16 m ~2 min CCW without Rotation Counterclockwise square, pure 90\u00b0 turns 2 ~16 m ~1 min <p>The dataset includes sixteen odometry calibration sequences in total:</p> <ul> <li>Four trajectory patterns (as described above)</li> <li>Repeated for each of the four 3D LiDAR sensors</li> </ul> <p>Sensor Independence</p> <p>Although odometry calibration parameters are independent of other sensors, including the 3D LiDARs, providing multiple sequences enhances the precision and reliability of the calibration process.</p> <p>Additional Uses</p> <p>These sequences can also serve as alternative data for extrinsic calibration algorithms, complementing or substituting the other 2 extrinsic calibration sequences when needed.</p>"},{"location":"content/dataset/sequences/calibration_sequences/#accessing-calibration-sequences","title":"Accessing Calibration Sequences","text":"<p>You can download calibration sequences using the IILABS 3D toolkit:</p> <pre><code>iilabs3d download &lt;output_directory&gt; &lt;sequence_name&gt; &lt;sensor_name&gt;\n</code></pre> <p>For example, to download the full excite calibration sequence for the Livox Mid-360 sensor:</p> <pre><code>iilabs3d download ~/slam_data calib_full_excite livox_mid_360\n</code></pre> <p>Downloading All Calibration Sequences</p> <p>To download all calibration sequences for all sensors: <pre><code>iilabs3d download ~/slam_data calib all\n</code></pre></p>"},{"location":"content/sensors/","title":"Sensors","text":"<p>This section provides detailed information about all the sensors used in the IILABS\u00a03D dataset, including 3D LiDARs, 2D laser scanners, and inertial measurement units (IMUs).</p> <p>For each sensor, we provide:</p> <ul> <li> Technical specifications  </li> <li> Usage details within the dataset  </li> <li> Manufacturer documentation  </li> <li> 3D models (where available)</li> </ul> <p>We organize the sensors into three main categories:</p>"},{"location":"content/sensors/#3d-lidars","title":"3D LiDARs","text":"<p>3D LiDAR sensors form the core of this benchmark. The dataset includes sequences from four different sensors, featuring both mechanical spinning and non-repetitive scanning designs.</p>"},{"location":"content/sensors/#2d-laser-scanners","title":"2D Laser Scanners","text":"<p>The dataset includes data from a Hokuyo UST-10LX, a time-of-flight 2D laser scanner. It was used alongside a 2D navigation stack to ensure consistent trajectory patterns across all 3D LiDAR recordings.</p>"},{"location":"content/sensors/#inertial-measurement-units-imus","title":"Inertial Measurement Units (IMUs)","text":"<p>IMUs enable accurate motion tracking and orientation estimation, making them a valuable complementary sensor in SLAM applications. In our dataset we include data from the Xsens MTi-630 AHRS to benchmark SLAM performance with and without IMU sensor fusion.</p>"},{"location":"content/sensors/imu/","title":"Inertial Measurement Units (IMUs)","text":"Specs Xsens MTi-630 AHRS Att. Acc. Roll (\u00ba) 0.2\u00ba (RMS) Att. Acc. Pitch (\u00ba) 0.2\u00ba (RMS) Att. Acc. Yaw (\u00ba) 1\u00ba (RMS) Gyro. Bias (\u00ba/s) 8 Gyro. Noise (\u00ba/s/\u221aHz) 0.007 Accel. Bias (\u03bcg) 10-15 Accel. Noise (\u00b5g/\u221aHz) 60 Rate (Hz) 400"},{"location":"content/sensors/imu/xsens_mti-630-ahrs/","title":"Xsens MTi-630 AHRS","text":""},{"location":"content/sensors/imu/xsens_mti-630-ahrs/#links","title":"Links","text":"<ul> <li>Xsens MTi-630 AHRS</li> </ul>"},{"location":"content/sensors/imu/xsens_mti-630-ahrs/#documents","title":"Documents","text":"<ul> <li>Xsens MTi-600 Series User Manual</li> <li>Xsens MTi-600 Series Developer Kit User Manual</li> <li>Xsens MTi-630 AHRS Datasheet</li> <li>Xsens MTi-630 AHRS 3D Models (STEP)</li> </ul>"},{"location":"content/sensors/imu/xsens_mti-630-ahrs/#gallery","title":"Gallery","text":""},{"location":"content/sensors/lidar2d/","title":"2D Laser Scanners","text":"Specs Hokuyo UST-10LX FoV (\u00ba) 270\u00ba Res. (\u00ba) 0.125\u00ba Type ToF Rate (Hz) 40 Range (m) 0.06-10"},{"location":"content/sensors/lidar2d/hokuyo_ust-10lx/","title":"Hokuyo UST-10LX","text":""},{"location":"content/sensors/lidar2d/hokuyo_ust-10lx/#links","title":"Links","text":"<ul> <li>Hokuyo UST-10LX</li> </ul>"},{"location":"content/sensors/lidar2d/hokuyo_ust-10lx/#documents","title":"Documents","text":"<ul> <li>Hokuyo UST-10LX Instruction Manual</li> <li>Hokuyo UST-10LX Datasheet</li> <li>Hokuyo UST-10LX-H01 Datasheet</li> <li>Hokuyo UST-10LX UST Communication Protocol Specification</li> <li>Hokuyo UST-10LX IP Discovery Tool</li> <li>Hokuyo UST-10LX 3D Model (STEP)</li> </ul>"},{"location":"content/sensors/lidar2d/hokuyo_ust-10lx/#gallery","title":"Gallery","text":""},{"location":"content/sensors/lidar3d/","title":"3D LiDARs","text":""},{"location":"content/sensors/lidar3d/#official-sensor-specifications-by-manufacturer","title":"Official Sensor Specifications (by Manufacturer)","text":"Specs Livox Mid-360 Ouster OS1-64 RoboSense RS-Helios-5515 Velodyne VLP-16 H/VFoV (\u00ba) 360\u00ba/59\u00ba 360\u00ba/45\u00ba 360\u00ba/70\u00ba 360\u00ba/30\u00ba HRes. (\u00ba) - 0.176/0.352/0.703\u00ba 0.1/0.2/0.4\u00ba 0.1-0.4\u00ba VRes. (\u00ba) - 0.71\u00ba \u2264 1.33\u00ba 2.00\u00ba VRange (\u00ba) -7 - +52\u00ba -22.5 - +22.5\u00ba -55 - +15\u00ba -15 - +15\u00ba VType non-repetitive rotational uniform rotational non-uniform rotational uniform #channels - 64 32 16 Rate (Hz) 10 10/20 5/10/20 5-20 Range (m) 0.1-70 0.3-120 0.2-150 100"},{"location":"content/sensors/lidar3d/#specs-as-used-in-our-dataset","title":"Specs as Used in Our Dataset","text":"Specs Livox Mid-360 Ouster OS1-64 RoboSense RS-Helios-5515 Velodyne VLP-16 H/VFoV (\u00ba) 360\u00ba/59\u00ba 360\u00ba/43\u00ba 360\u00ba/70\u00ba 360\u00ba/30\u00ba HRes. (\u00ba) - 0.176\u00ba 0.1\u00ba 0.2\u00ba VRes. (\u00ba) - 0.71\u00ba \u2264 1.33\u00ba 2.00\u00ba VRange (\u00ba) -7 - +52\u00ba -21.1 - +21.27\u00ba -55 - +15\u00ba -15 - +15\u00ba VType non-repetitive rotational uniform rotational non-uniform rotational uniform #channels - 64 32 16 Rate (Hz) 10 10 10 10 Range (m) 0.1-70 0.3-120 0.2-150 100"},{"location":"content/sensors/lidar3d/livox_mid-360/","title":"Livox Mid-360","text":""},{"location":"content/sensors/lidar3d/livox_mid-360/#links","title":"Links","text":"<ul> <li>Livox Mid-360</li> </ul>"},{"location":"content/sensors/lidar3d/livox_mid-360/#documents","title":"Documents","text":"<ul> <li>Livox Mid-360 User Manual</li> <li>Livox Mid-360 Quick Start Guide</li> <li>Livox Mid-360 3D Models (STEP)</li> </ul>"},{"location":"content/sensors/lidar3d/livox_mid-360/#gallery","title":"Gallery","text":""},{"location":"content/sensors/lidar3d/ouster_os1-64/","title":"Ouster OS1-64","text":""},{"location":"content/sensors/lidar3d/ouster_os1-64/#links","title":"Links","text":"<ul> <li>Ouster OS1</li> </ul>"},{"location":"content/sensors/lidar3d/ouster_os1-64/#documents","title":"Documents","text":"<ul> <li>Ouster OS1 Rev-C User Manual</li> <li>Ouster OS1 Rev-C Datasheet</li> <li>Ouster OS1 Rev-C 3D Models (STEP)</li> </ul>"},{"location":"content/sensors/lidar3d/ouster_os1-64/#gallery","title":"Gallery","text":""},{"location":"content/sensors/lidar3d/robosense_rs-helios-5515/","title":"RoboSense RS-Helios-5515","text":""},{"location":"content/sensors/lidar3d/robosense_rs-helios-5515/#links","title":"Links","text":"<ul> <li>RoboSense Helios Series</li> </ul>"},{"location":"content/sensors/lidar3d/robosense_rs-helios-5515/#documents","title":"Documents","text":"<ul> <li>RoboSense Helios-32 User Manual</li> <li>RoboSense Helios-5515 User Manual</li> <li>RoboSense Helios-Series Datasheet</li> <li>RoboSense Helios-5515 3D Models (STEP)</li> </ul>"},{"location":"content/sensors/lidar3d/robosense_rs-helios-5515/#gallery","title":"Gallery","text":""},{"location":"content/sensors/lidar3d/velodyne_vlp-16/","title":"Velodyne VLP-16","text":""},{"location":"content/sensors/lidar3d/velodyne_vlp-16/#links","title":"Links","text":"<ul> <li>Velodyne VLP-16</li> </ul>"},{"location":"content/sensors/lidar3d/velodyne_vlp-16/#documents","title":"Documents","text":"<ul> <li>Velodyne VLP-16 User Manual</li> <li>Velodyne VLP-16 Puck Datasheet</li> <li>Velodyne VLP-16 Interface Box</li> </ul>"},{"location":"content/sensors/lidar3d/velodyne_vlp-16/#gallery","title":"Gallery","text":""}]}